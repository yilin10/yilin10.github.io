<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Thoughts. Notes.">
<meta property="og:type" content="website">
<meta property="og:title" content="Parking Site">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Parking Site">
<meta property="og:description" content="Thoughts. Notes.">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Yilin">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Parking Site</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Parking Site</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">A castle on the cloud.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/28/review2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/28/review2/" class="post-title-link" itemprop="url">MachineLearning_Review Outline</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-28 14:45:41 / Modified: 12:45:41" itemprop="dateCreated datePublished" datetime="2020-06-28T14:45:41Z">2020-06-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="RL-knowledge-List-collection-title"><a href="#RL-knowledge-List-collection-title" class="headerlink" title="RL knowledge List {.collection-title}"></a>RL knowledge List {.collection-title}</h4><p>  Name                                                                                                                                                                       Tags                keypoints</p>
<hr>
<p>  <a href="https://www.notion.so/Value-of-the-action-dc23f4d068974f1e8f23defd171f684e" target="_blank" rel="noopener">Value of the action</a>                                                                          W1_MAB             Value of action = <strong>expected reward when the action is taken,</strong> q * (a) are defined as the expected<strong>reward R_t</strong> from the action A_t but q*(a) we dont know→ we need to estimate it<br>  <a href="https://www.notion.so/Sample-Average-Method-d29ee43e3a82486397aa066fd57fb934" target="_blank" rel="noopener">Sample-Average Method</a>                                                                      W1_MAB             Q_t(a) are defined as (sum of rewards when a taken prior to t)/(number of times a taken prior to t),<br>  <a href="https://www.notion.so/the-doctor-example-628183170f064f1cb5d96a2eb55d33c1" target="_blank" rel="noopener">the doctor example</a>                                                                            W1_MAB             As the doctor <strong>observe more patients</strong>, the estimated approach the true action value <strong>(**</strong>the sample average method<strong>**)</strong><br>  <a href="https://www.notion.so/Action-Selection-d40dc90743ac40948901191d21a9e0b1" target="_blank" rel="noopener">Action Selection</a>                                                                                W1_MAB             <strong>The greedy action</strong> → they think it currently is the <strong>best</strong>! → has the largest estimated action value <strong>The agent is trying to get the most reward it can!</strong><br>  <a href="https://www.notion.so/Balance-b94cf7bea3ff401391facb960862c0c4" target="_blank" rel="noopener">Balance</a>                                                                                                  W1_MAB             short-term reward: choose greedy action → gamma = 0, not thinking about future at all long term reward: choose non-greedy action→ sacrifice immediate reward→ hopping to get more information about other actions → gamma = 1, thinking about future gamma: <strong>discount factor</strong><br>  <a href="https://www.notion.so/Exploration-exploitation-Dilemma-b8d53016554e4a6ca9165464588a3792" target="_blank" rel="noopener">Exploration- exploitation Dilemma</a>                                               W1_MAB             conflict? balance?<br>  <a href="https://www.notion.so/Estimate-action-value-incrementally-f872794d04ce4d0eadb0ef7c88f0df2e" target="_blank" rel="noopener">Estimate action value incrementally</a>                                          W1_MAB             <strong>Web advertisement problem</strong><br>  <a href="https://www.notion.so/Incremental-Update-Rule-fe87835e60544143a3b3f7632d711e4b" target="_blank" rel="noopener">Incremental Update Rule</a>                                                                                      Q_n+1 ⇒ 1/n * Sum(Ri)| i = 1 to n ⇒ 1/n *(R_n+ Sum(Ri)| i = 1 to n-1) <strong>Q_n+1 = Q_n + ( Rn -Q_n)/n**</strong>New Estimate ← Old Estimate + StepSize (Target -OldEstimate)<em>*<br>  <a href="https://www.notion.so/Non-stationery-Bandit-Problem-c999008dfb284f3a91eb6dfdfd4e3cbf" target="_blank" rel="noopener">Non- stationery Bandit Problem</a>                                                     W1_MAB             ???<br>  <a href="https://www.notion.so/What-is-the-Trade-Off-2145435420e14fa3a83792428fb068fd" target="_blank" rel="noopener">What is the Trade Off</a>                                                                      W1_MAB             Exploration: improve knowledge for long term benefit Exploitation: exploit short term benefit WE can not do both simultaneously<br>  <a href="https://www.notion.so/Epsilon-Greedy-Action-Selection-9206fa15eb684f0bae3c1c758a77b011" target="_blank" rel="noopener">Epsilon-Greedy Action Selection</a>                                                  W1_MAB             ROLL a DICE <strong>epsilon: the possibility of choosing to explore</strong><br>  <a href="https://www.notion.so/Optimistic-Initial-Values-0fcc1cac55f1443680d6b88ca93db815" target="_blank" rel="noopener">Optimistic Initial Values</a>                                                              W1_MAB             encourage exploration in early steps<br>  <a href="https://www.notion.so/Upper-Confidence-Bound-Action-Selection-d5a8d824db284edda1667e7977f4ec5f" target="_blank" rel="noopener">Upper Confidence Bound Action Selection</a>                                  W1_MAB             <strong>UCB = Upper Confidence Bound Use to decide the Action Selection Process,**</strong>between<strong><strong>Exploration</strong></strong>&amp;<strong><strong>Exploitation</strong></strong>How UCB action-selection uses<strong><strong>uncertainty</strong></strong>in<strong><strong>estimation</strong></strong>to drive exploration**<br>  <a href="https://www.notion.so/The-difference-of-MAB-and-MDP-832560e6d30a4e3e8998823d09ceb653" target="_blank" rel="noopener">The difference of MAB and MDP</a>                                                      W2_MDP             MAB: same situation at each time→ single state→ the same action is always optimal <strong>MDP</strong>: different situation→ different response→ action chosen affect the amount of reward we can get into the future<br>  <a href="https://www.notion.so/Example-d3c8c74f287b409eaae61c71a44c2688" target="_blank" rel="noopener">Example</a>                                                                                                  W2_MDP             <strong>Bandit algorithm</strong> tells a <strong>policy</strong>(which treatment to choose) for each trial. If he choose the <strong>sub optimal</strong>medicine (i.e., performance of the medicine is less than other one) to treat the patient, then the cumulative performance will decrease. Unlike bandit, <strong>In MDP when you take an action, you will be in different state. MAB = MDP with**</strong>single<strong><strong>state</strong></strong>Situation = state, the action A_t change the state in MDP, create a new state St+1**<br>  <a href="https://www.notion.so/What-is-MDP-8a72bfda58964606b7f839164d346eb0" target="_blank" rel="noopener">What is MDP?</a>                                                                                         W2_MDP             carrot / other vegetable , but different situation calls for different reactions carrot(lion) <strong>think about long term impact of our decisions</strong><br>  <a href="https://www.notion.so/How-to-represent-the-dynamics-of-an-MDP-1dbd4649162c4287b063d4b2f53a09e9" target="_blank" rel="noopener">How to represent the dynamics of an MDP</a>                                  W2_MDP             dynamics , transition dynamics from one state → to another<br>  <a href="https://www.notion.so/Formalization-of-MDP-0feedc1ade444ece85e37c7669a02dcb" target="_blank" rel="noopener">Formalization of MDP</a>                                                                        W2_MDP             MDP formalization is flexible and abstract. \</em> states can be low level abstraction or high level abstractions, so it can be usde in various usages. (e.g. pixels, or object description in a photo) * time step can be short or very large<br>  <a href="https://www.notion.so/What-s-the-relationship-of-MDP-and-RL-20586ce962ee4a01b8d8bef531637cc4" target="_blank" rel="noopener">What’s the relationship of MDP and RL?</a>                                     W2_MDP             RL : solve control task or prediction task MDP: sequential decision making problems, forma lize a wide range of this problems<br>  <a href="https://www.notion.so/RL-f5cfeebb513c40be8db64035d2331622" target="_blank" rel="noopener">RL</a>                                                                                                            W2_MDP             RL: the goal for the agent is to maximize the future reward describe how the reward are related to the goal of the agent: long term goal, reward and future motion <strong>Returen Gt are defined as R_t+1 + R_t+2 + R_t+3 +…</strong> E(G) =E (sum(R…..)) maximize the expected Return → should be finite<br>  <a href="https://www.notion.so/identify-episodic-tasks-cdfb8f18d9cf4a488625d186f0d02455" target="_blank" rel="noopener">identify episodic tasks</a>                                                                  W2_MDP             naturally breaks into chucks called episodes each episode begins independently of how the previous one ends. e.g. <strong>Chess Game</strong><br>  <a href="https://www.notion.so/What-is-a-Reward-Hypothesis-c8615c73760f44eba669dcc8fd63982d" target="_blank" rel="noopener">What is a Reward Hypothesis?</a>                                                         W2_MDP             maximize the expected value expected future retuen That all of what we mean by goals and purposes can be well thought of as <strong>maximization of the expected valu</strong>e of the <strong>cumulative sum</strong> of <strong>a received scalar signal****</strong>(<strong>reward</strong>). Goals and purpose can be thought of as the maximization of the expected value of the cumulative sum of scalar rewards received<br>  <a href="https://www.notion.so/Continuing-Tasks-43f184f816064caa836527dead3de930" target="_blank" rel="noopener">Continuing Tasks</a>                                                                                W2_MDP<br>  <a href="https://www.notion.so/Examples-of-Episodic-and-continuing-tasks-684d286985d6486dbbd9bf3a15a7bdf5" target="_blank" rel="noopener">Examples of Episodic and continuing tasks</a>                              W2_MDP             Epsodic: chess game regardless of how the game end, the new game states indepently<br>  <a href="https://www.notion.so/W2-summary-bd86d42e90f24c0fa271aafdffc15e33" target="_blank" rel="noopener">W2 summary</a>                                                                                            W2_MDP             MDP can formalize all problems in RL { State, Action, Rewards} Long term consequences, Actin → Future States + Rewards <strong>The Goal of RL: maximize**</strong>Total future reward → balance immediate reward with long term actions expected discounted sum of future rewards<em>*<br>  <a href="https://www.notion.so/Discount-56ad4836c9da412ebd42926bdc7ec027" target="_blank" rel="noopener">Discount</a>                                                                                                W2_MDP             0&lt;gamma &lt;1 , the return remains finite gamma → 1, care about short term reward gamma→0 , we care about long term reward<br>  <a href="https://www.notion.so/Solve-RL-650caf9eefc04143b91281105b262fda" target="_blank" rel="noopener">Solve RL</a>                                                                                                W2_MDP             first step → MDP problems<br>  <a href="https://www.notion.so/Value-Functions-Bellman-Equations-2f8e6a71506747c0becabc565377bca3" target="_blank" rel="noopener">Value Functions, Bellman Equations</a>                                             W3_Policy&amp;Belman   Once the <strong>problem is formulated as an MDP</strong>, finding the<strong>optimal policy</strong> is more efficient when using <strong>value functions</strong>. This week, you will learn the definition of policies and value functions, as well as Bellman equations, which is the key technology that all of our algorithms will use.<br>  <a href="https://www.notion.so/Policy-6df27ee5811a412abfc8dab0c5421988" target="_blank" rel="noopener">Policy</a>                                                                                                    W3_Policy&amp;Belman   choose an action → reward + next state A policy is a distribution over actions for each possible state.<br>  <a href="https://www.notion.so/stochastic-and-deterministic-policy-e60a6adcf3834613ab160ff0dcd9cf48" target="_blank" rel="noopener">stochastic and deterministic policy</a>                                          W3_Policy&amp;Belman   <strong>Deterministic Policy: A Policy maps each states to a single action.**</strong>probability of 1** Policy(s) = a, States = s0, s1, s2 ; Actions = a0, a1, a2 (use Pie) <strong>Pi(s0) → a1, Pi(s1)→a0, Pi(s2)→a0.</strong> of course you can have same action for different state. In general, a policy assigns possibility to each action in each state. <strong>Pi(a|s) → represent a probability of selection of action a in state S Stochastic Policy: multi action be selected with non zero probability distribution → select actions in state S.**</strong>The stochastic policy might take the same step as the deterministic policy did.→ reach the Goal. Exploration/Exploitation trade-off (Epsilon greedy): can be useful for exploration**<br>  <a href="https://www.notion.so/generate-examples-of-valide-policies-for-MDP-10cb945ef35147df960d7c654cc3e11d" target="_blank" rel="noopener">generate examples of valide policies for MDP</a>                        W3_Policy&amp;Belman   It is important that Policy only depends on the current state, not on the<strong>time and previous state Valid policies:</strong>You don’t know about <strong>previous state</strong> anymore!!!!<strong>**You dont know</strong>time! Invalide Policies:<strong>The action depends on **something other than the state</strong><br>  <a href="https://www.notion.so/Summary-3686ba3bf2bd4c08a020b3b8a4f86442" target="_blank" rel="noopener">Summary</a>                                                                                                  W3_Policy&amp;Belman   <strong>A policy maps**</strong>the current state<strong>**onto a set of possibilities for taking each action Policy only depends on the current state</strong><br>  <a href="https://www.notion.so/Value-Functions-35ba82844c274d6487a04fd3de1c18db" target="_blank" rel="noopener">Value Functions</a>                                                                                  W3_Policy&amp;Belman   Delayed Reward: short term gain / long term gain? How to get a policy that achieve the most reward in the long term run? → Value Function is introduced to solve this issue.<br>  <a href="https://www.notion.so/Describe-the-role-of-state-value-action-value-function-ed7b70a3921d49d5bcbe34e25950aff2" target="_blank" rel="noopener">Describe the role of state value/ action value function</a>   W3_Policy&amp;Belman   State Value Function: v(s) are defined as Expectation of (Future Reward an agent can expect to receive stating from a particular state) Action Value Function q_pi(s,a) are defined as Expected_pi (G_t | S_t =S, A_t = a) Value function predict rewards into the future<br>  <a href="https://www.notion.so/the-relation-between-value-functions-and-policies-16206bc9699048ffa6ea7edc530e5771" target="_blank" rel="noopener">the relation between value functions and policies</a>              W3_Policy&amp;Belman   action, state, policy<br>  <a href="https://www.notion.so/examples-of-valid-value-function-for-a-given-MDP-e32f7033af4f4d2ca73013b489205c9e" target="_blank" rel="noopener">examples of valid value function for a given MDP</a>                W3_Policy&amp;Belman   Chess game Reward : win +1; draw or loss 0 (not enough information to tell us how to achieve the goal) Value Function: Value V_pi(s) → <strong>probability for winning</strong> if we follow <strong>current policy Pi</strong>, at the <strong>current state</strong><br>  <a href="https://www.notion.so/Bellman-equation-611f4bc9b7544e02ab19cb5f15feacb3" target="_blank" rel="noopener">Bellman equation</a>                                                                                W3_Policy&amp;Belman   value of state and its possible successor derive <strong>Bellman equation</strong> ← <strong>state value function</strong> / <strong>action value function Understand how Bellman equation relates →**</strong>current and future values V_pi(s) are defined as the E_pi (Gt| St = s)** and G_t = R_t + gamma \</em> G_t+1<br>  <a href="https://www.notion.so/Why-Bellman-equation-c82b8550492f412e8c5ac1fb85b3d557" target="_blank" rel="noopener">Why Bellman equation</a>                                                                        W3_Policy&amp;Belman   we can only directly solve small DMP problems use Bellman equation, possible to solve chess problems, scale up to large problems<br>  <a href="https://www.notion.so/Optimal-Policies-c0193e08099a440ab6f5c9a2def6ae79" target="_blank" rel="noopener">Optimal Policies</a>                                                                                W3_Policy&amp;Belman   Policy→ how an agent behave → Value Function What’s the goal of RL: We want to find the best policy in the long run! How to find → we can get different Value on different Policy →<strong>In some state, Policy had different value→ pi(1) ≥pi(2)</strong> iff line 1 is<strong>above</strong> line 2 <strong>An optimal policy**</strong>PI*<strong><strong>is that it</strong></strong>always has the highest possible value<strong><strong>in every state. There’s always</strong></strong>at least one Optimal policy( maybe more)<strong>Proof: Pi(3) = Pi(1) , Pi(2) , Optimal → pi *⇒ alwasy exist optimal policy!!!!<br>  <a href="https://www.notion.so/How-to-find-Optimal-policy-a8b4de6e66df4c53a2ccd4a47ad2c968" target="_blank" rel="noopener">How to find Optimal policy</a>                                                            W3_Policy&amp;Belman   simple question→ Brute Force Search complex→how to optimize the search in the policy space?→ Bellman Optimality Equations<br>  <a href="https://www.notion.so/W3-Summary-a8d0ef8a26e24079ae570cb5a3c11d70" target="_blank" rel="noopener">W3 Summary</a>                                                                                            W3_Policy&amp;Belman   what is a policy→ current state → tell an agent how to behave determinate: map sate → an action stochastic: map each state to a probability distribution value function on States and Actions, probability to win<br>  <a href="https://www.notion.so/The-optimal-state-value-function-4121337c33f84b53bf5c80751b0397c8" target="_blank" rel="noopener">The optimal state-value function:</a>                                               W3_Policy&amp;Belman   **Is unique in every finite MDP</strong> The Bellman optimality equation is actually <strong>a system of equations</strong>, one for each state, so if there are N states, then there are N equations in N unknowns. If the dynamics of the environment are known, then in principle one can solve this system of equations for the optimal value function using any one of a variety of methods for solving systems of nonlinear equations. All optimal policies share <strong>the same optimal state-value function</strong>.<br>  <a href="https://www.notion.so/What-is-DP-fa20f67b6bd94e529091357e7feb79fb" target="_blank" rel="noopener">What is DP</a>                                                                                            W4_DP              Dynamic Programming function p can be used to solve <strong>Policy evaluation and Control problem</strong><br>  <a href="https://www.notion.so/Policy-Evaluation-Control-5c58fbb8bd2e4a5fbecc3e5e9ebd2e6c" target="_blank" rel="noopener">Policy Evaluation &amp; Control</a>                                                            W4_DP              distinction between policy evaluation and control Control ⇒task of finding a policy to obtain as much as possible DP problems use <strong>Bellman equations</strong> to define<strong>iterative algorithms</strong> for both policy evaluation and control<br>  <a href="https://www.notion.so/Policy-Evaluation-823e7262af1f48c6be233f4a4196c2ac" target="_blank" rel="noopener">Policy Evaluation</a>                                                                              W4_DP              How good pi is? → pi → V_pi pi, p,gamma → DP → v_pi optimal policy! Control task complete <strong>iff</strong> <strong>current policy = optimal policy V_pi → policy evaluation pi * → control algorithms → compute value → DP</strong><br>  <a href="https://www.notion.so/Iterative-Policy-Evaluation-833c8f050f4343dfa2a4837f8f9183e4" target="_blank" rel="noopener">Iterative Policy Evaluation</a>                                                          W4_DP              DP are working as turning <strong>Bellman Equation</strong> into<strong>update rules. First algorithm in DP → Iterative Policy Algorithms equation → iterative → get a approximate value → closer and closer to the value function(</strong>updated rule)Each iterationS → Sweep →v_pi V_pi is the unique solution to the bellman Equations<br>  <a href="https://www.notion.so/Policy-Improvements-ea005f6f425745f1b8f9c0be43f83a98" target="_blank" rel="noopener">Policy Improvements</a>                                                                          W4_DP<br>  <a href="https://www.notion.so/Policy-Iteration-5bd29e0376944fb3b02991a326423f21" target="_blank" rel="noopener">Policy Iteration</a>                                                                                W4_DP              You randomly select a <strong>policy</strong> and f<strong>ind value function</strong> corresponding to it , then find a <strong>new (improved) policy based on the previous value function</strong>, and so on this will lead to <strong>optimal policy</strong><br>  <a href="https://www.notion.so/sequential-decision-making-problem-fb0d78a82bd14910855bd36dfdb2ec11" target="_blank" rel="noopener">sequential decision making problem</a>                                            W2_MDPsocrative    Long-term goal are generally <strong>more important</strong>than short-term consequences Agent does not always know <strong>completely the state of the environment e.g., partial observable problems</strong><br>  <a href="https://www.notion.so/MDP-1127e71bd39f4cbd88f78124d65d1bfe" target="_blank" rel="noopener">MDP</a>                                                                                                          W2_MDPsocrative    State Space Action Space One-Step Dynamics In continuing tasks the discount factor must be smaller than 1<br>  <a href="https://www.notion.so/Explain-briefly-what-is-the-reward-hypothesis-edb58fb27e3f45b1b085f3390c9d2873" target="_blank" rel="noopener">Explain briefly what is the reward hypothesis</a>                      W2_MDPsocrative    The reward hypothesis says that the agent is going to maximize the value of expected value of the cumulative sum of the received reward on the current state<br>  <a href="https://www.notion.so/Bellman-Expectation-Equations-b977456165294004ad2664f411cdbddd" target="_blank" rel="noopener">Bellman Expectation Equations</a>                                                      W2_MDPsocrative    allows to evaluate a policy might be computationaly infeasible for large problems requires the knowledge of one step dynamics<br>  <a href="https://www.notion.so/Why-DP-8d40a04573c44b5d9d5cd48ac23eb713" target="_blank" rel="noopener">Why DP</a>                                                                                                    W4_DPsocrative     solving MDP is <strong>not easy</strong><br>  <a href="https://www.notion.so/Define-sweep-in-Iterative-Policy-Evaluation-48ac5ab3a2bd474c9edffdfc2c534422" target="_blank" rel="noopener">Define sweep in Iterative Policy Evaluation</a>                          socrative           first we have an initial step to estimation the value of the policy, then we use an iterative approach to update an estimation for the policy evaluation function, So we have a V’_pi to update the V_pi value at each<strong>k step**</strong>for all states = at each<strong><strong>iteration of the algorithm</strong></strong>, it<strong><strong>updates the value function</strong></strong>for all the states , it<strong><strong>“sweeps” through the state space</strong></strong>of the problem**<br>  <a href="https://www.notion.so/4c9f4508021b40cd869c68195b54d143" target="_blank" rel="noopener">Untitled</a>                                                                                                                             </p>
<h4 id="Slides-Review-collection-title"><a href="#Slides-Review-collection-title" class="headerlink" title="Slides Review {.collection-title}"></a>Slides Review {.collection-title}</h4><p>  Name                                                                                                                                                Tags                            Keypoints</p>
<hr>
<p>  <a href="https://www.notion.so/Bias-Variance-Tradeoff-8f2cb4f893334f95be70505772073a81" target="_blank" rel="noopener">Bias-Variance Tradeoff</a>                                             05_ModelEvaluation/Selection   How to evaluate a model, can not use loss function The <strong>Bias-Variance</strong> is a framework to analyze the performance of models. 1. <strong>variance</strong>measures <strong>the difference between each model learned from a particular dataset</strong> and what we expect to learn. More sample / simpler model → decrease Variance 2. <strong>bias</strong> measures the difference between<strong>truth</strong> (𝑓) and what we expect to learn: more complex model→ decrease Bias<br>  <a href="https://www.notion.so/Model-Assessment-befa4d00bf174472880fc242701dd437" target="_blank" rel="noopener">Model Assessment</a>                                                         05_ModelEvaluation/Selection   high variance : under fitting high bias: overfitting <strong>low bias, low variance: good !</strong><br>  <a href="https://www.notion.so/Regularization-and-Bias-Variance-620f0729dc7748a3a0c84bbc6c9db68a" target="_blank" rel="noopener">Regularization and Bias-Variance</a>                         05_ModelEvaluation/Selection   <strong>The Bias-Variance decomposition explains why regularization allows to improve the error on unseen data.**</strong>Lasso outperforms Ridge regression when few features are related to the output<em>*<br>  <a href="https://www.notion.so/Training-Error-Prediction-Error-4fec80687ae1405295f4d8f57e9c0d3e" target="_blank" rel="noopener">Training Error/Prediction Error</a>                           05_ModelEvaluation/Selection   Training Error: t_n-y(x_n) Prediction Error: (t_n-y(x_n)) \</em> p(x,t)<br>  <a href="https://www.notion.so/In-practice-26cbf101a2654236a21f51690a662d82" target="_blank" rel="noopener">In practice</a>                                                                   05_ModelEvaluation/Selection   1. Split randomly data into a training set and test set 2. Optimize model parameters using the training set 3. Estimate the prediction error using the test set <strong>high bias:</strong>training error is close to test error but they are both higher than expected <strong>high variance:</strong>training error is smaller than expected and it slowly approaches the test error<br>  <a href="https://www.notion.so/data-split-a6ad270dd822425496dd30702bc8adfa" target="_blank" rel="noopener">data split</a>                                                                     05_ModelEvaluation/Selection   Training Data → train model get parameter Validation Data→ <strong>validation error</strong> → select model with validation step → Test Data to <strong>estimate prediction error</strong> <strong>→ raise 2 problems</strong> 1. enough validation data → less training data 2. overfitting ? How to solve ⇒ Cross Validation <strong>LOOCV (</strong> lower bias but expensive to compute)/<strong>K-Fold cross validation (s</strong>plit in to K-folds, little bias, cheaper to compute<strong>)</strong><br>  <a href="https://www.notion.so/How-to-choose-the-model-4cb3c28bb2364a9ab14e33ae4ad3b7db" target="_blank" rel="noopener">How to choose the model</a>                                           05_ModelEvaluation/Selection   <strong>Reducing the variance</strong> choose right feature: the most <strong>effective</strong> subset of all the possible features dimensional reduction:<strong>lower- dimensional</strong> space <strong>Regularization</strong>: the values of the parameters are shrunked toward zero<br>  <a href="https://www.notion.so/No-free-lunch-Theorems-71cf25067f6a4777a62e7a3d20b5b7fb" target="_blank" rel="noopener">No free lunch Theorems</a>                                             05_ModelEvaluation/Selection   Y<strong>our favourite learner will not be always the best!</strong><br>  <a href="https://www.notion.so/Feature-Selection-353b446cd83842fb8553792d034e9483" target="_blank" rel="noopener">Feature Selection</a>                                                       05_ModelEvaluation/Selection   AIC, BIC, AdjusterR2, etc. Cross-Validation<br>  <a href="https://www.notion.so/Dimensionality-reduction-e11cc1df66704b09800f98141bda1bec" target="_blank" rel="noopener">Dimensionality reduction</a>                                         05_ModelEvaluation/Selection   ⚠️<strong>Principal Component Analysis (PCA) P38**</strong>Dimensionality reduction aims at reducing the dimensions of input space, but it differs from feature selection in two major respects: it uses all the features and maps them into a lower-dimensionality space it is an unsupervised approach!<em>*<br>  <a href="https://www.notion.so/Bagging-and-Boosting-3829f02f39ac426f942df256376da4d1" target="_blank" rel="noopener">Bagging and Boosting</a>                                                 05_ModelEvaluation/Selection   \</em> Bootstrap Aggregation= <strong>Bagging</strong>（自主聚合）→ decrease high variance → suitable foe learner that is <strong>low bias and high variance/ overfitting problem ← bagging is suitable to decrease variance**</strong>* Boosting: high bias, the learner is not good enough ← need to fix it, boosting !!!!!!! → decrease bias/ still use simple learner/ keep the same variance (<em>* still using weak learners: decision trees …<strong>)</strong> AdaBoost<br>  <a href="https://www.notion.so/VC-dimension-f39133a2bf6e4aeb8bc505685ea07b9c" target="_blank" rel="noopener">VC dimension????</a>                                                             06_LearningTheory              <strong>⚠️VC dimension</strong><br>  <a href="https://www.notion.so/Kernel-Ridge-Regression-1d111df2ebf04672b073894318f67700" target="_blank" rel="noopener">Kernel Ridge Regression</a>                                           07_KernalMethods               看图片分布辨别用什么方法，linear/kernel<br>  <a href="https://www.notion.so/Kernel-Design-86ae42aa55f1411b942389b0c4add267" target="_blank" rel="noopener">Kernel Design</a>                                                               07_KernalMethods<br>  <a href="https://www.notion.so/Kernel-Regression-57086a92341a45538f2e19a266ba2a13" target="_blank" rel="noopener">Kernel Regression</a>                                                       07_KernalMethods<br>  <a href="https://www.notion.so/Kernel-Trick-40b6431dee7b4e539806943994c2fde5" target="_blank" rel="noopener">Kernel Trick</a>                                                                 07_KernalMethods               can be used in …. Ridge Regression K-NN Regression Perceptron (Nonlinear) <strong>PCA</strong> Support Vector Machines … even <strong>Generative Models</strong><br>  <a href="https://www.notion.so/What-is-MAB-e48b9aa755d8477f94b026394f994327" target="_blank" rel="noopener">What is MAB?</a>                                                                  13_MAB                         <strong>Multi-arm bandit! far-sighted: gamma exploration/exploitation</strong><br>  <a href="https://www.notion.so/different-categories-a09681f99b334600b3ca172992c2a31e" target="_blank" rel="noopener">different categories</a>                                                 13_MAB                         <strong>- Determistic</strong> <strong>- Stochastic { frequentist MAB , Bayesian }**</strong>-<strong><strong>Adversarial Infinite time horizon: need to explore to gather more information</strong></strong>to find the best overall action<strong><strong>Finite time horizon: need to</strong></strong>minimize short term loss<strong><strong>because</strong></strong>uncertainty**<br>  <a href="https://www.notion.so/real-example-de11131ff78146268a96750070e7c245" target="_blank" rel="noopener">real example</a>                                                                 13_MAB                         clinic test on new treatments! game playing slot machine Oil drilling new/unexplored/best/optimal<br>  <a href="https://www.notion.so/epsilon-greeedy-7cf057e16a104b32b23494fa0ebfce1c" target="_blank" rel="noopener">epsilon greeedy</a>                                                           13_MAB                         1-e → greedy, instant reward; e → explore<br>  <a href="https://www.notion.so/softmax-2464e477392a4d86bd6f5c5aef1472b3" target="_blank" rel="noopener">softmax</a>                                                                           13_MAB                         <strong>Weights the actions according to its estimated value Q(a|s) τ is a temperature parameter which decreases over time</strong> Even if these algorithms converge to the <strong>optimal choice</strong>, we do not know how much we lose during the learning process<br>  <a href="https://www.notion.so/MDP-relate-to-MAB-7829c890c85a4e979c68bf2a935fef1e" target="_blank" rel="noopener">MDP -relate to - MAB</a>                                                    13_MAB                         MDP → special case ( <strong>when the sate is single</strong>) → MAB State, Arm , Transition Matrix, Reward Function, discount factor(<strong>0&lt; gamma &lt;1</strong> ), initial probability(<strong>optimistic estimation</strong>)<br>  <a href="https://www.notion.so/Goal-6ceac9d071584176b7e3cd15726bbeea" target="_blank" rel="noopener">Goal</a>                                                                                 13_MAB                         maximize expectation value also minimize regret<br>  <a href="https://www.notion.so/Formulation-7e043a9e69bf45129d5a5abefc31ec44" target="_blank" rel="noopener">Formulation</a>                                                                   13_MAB                         <strong>1. Frequentist formulation</strong> R(a1), . . . R(aN ) are unknown parameters <strong>A policy selects at each time step an arm based on the observation history</strong> <strong>2. Bayesian formulation</strong> R(a1), . . . R(aN ) are random variables with<strong>prior distributions</strong> f1,…,fN <strong>A policy selects at each time step an arm based on the observation history and**</strong>on the provided priors**<br>  <a href="https://www.notion.so/Optimism-in-face-of-Uncertainty-914d8a52ff584cd5af507c7b47acfbed" target="_blank" rel="noopener">Optimism in face of Uncertainty</a>                           13_MAB                         uncertain → <strong>explore</strong>→ get information &amp; some loss in short term<br>  <a href="https://www.notion.so/Upper-confidence-Bound-Approach-f53fae565baf41bf96695c7d83ae9f83" target="_blank" rel="noopener">Upper confidence Bound Approach</a>                           13_MAB                         ⭐️statistic approach → get a balance between <strong>exploration and exploitation</strong>the bound length Bt(ai) depends on how much information we have on an arm, i.e., the number of times we pulled that arm so far Nt(ai)<br>  <a href="https://www.notion.so/UCB1-0d707d9c277241b7bf093f777d8ff05d" target="_blank" rel="noopener">UCB1</a>                                                                                 13_MAB                         ⭐️!!!!!!!!<br>  <a href="https://www.notion.so/Thompson-Sampling-13fbbf7f9fb34ebfb9fd9798f6eda574" target="_blank" rel="noopener">Thompson Sampling</a>                                                       13_MAB                         😇<strong>Pull</strong> the arm a with the highest sampled value <strong>Update</strong>the prior incorporating the new information Thompson Sampling → a method to solve MAB problem →<strong>optimal balance about explore/ exploit</strong> <strong>1. sample from distribution to generate reward estimate</strong> 2. pick the arm with highest expectation 3. apply the arm and observe the reward 4. update distribution<br>  <a href="https://www.notion.so/EXP3-175eca0901cf4ee59bfef7efea658765" target="_blank" rel="noopener">EXP3</a>                                                                                 13_MAB                         💥<strong>Variation of the Softmax algorithm</strong> Probability of choosing an arm,<br>  <a href="https://www.notion.so/Why-DP-c52678b3f3594b5780b40a7eb61efd36" target="_blank" rel="noopener">Why DP</a>                                                                             10_DP                          in order to find optimal policy of RL problem formulated in MDP, we need to find algorithms to evaluate policy value For small MDP problem→we can use <strong>brute force search</strong> For bigger MDP problem → <strong>DP can be used</strong> Dynamic Programming (DP) is a method that allow to <strong>solve a complex problem</strong> by <strong>breaking it down into**</strong>simpler sub-problems in a recursive manner** + Bellman Equation→ finite→unique Optimal solution→ <strong>pi*</strong><br>  <a href="https://www.notion.so/Policy-Evaluation-7f85d8a60b4142009608d5f2dea25a89" target="_blank" rel="noopener">Policy Evaluation</a>                                                       10_DP<br>  <a href="https://www.notion.so/Policy-Improvement-cdd84541c18d441d8d6121da16b94861" target="_blank" rel="noopener">Policy Improvement</a>                                                     10_DP<br>  <a href="https://www.notion.so/Policy-Iteration-94ed50a034b94fbb8f4bb0a66b971101" target="_blank" rel="noopener">Policy Iteration</a>                                                         10_DP<br>  <a href="https://www.notion.so/Generalized-Policy-Iteration-efd165addafa481d97b0d890a9346613" target="_blank" rel="noopener">Generalized Policy Iteration</a>                                 10_DP<br>  <a href="https://www.notion.so/Efficiency-of-DP-afb0dd98341347bebbd7ad32dab3407a" target="_blank" rel="noopener">Efficiency of DP</a>                                                         10_DP<br>  <a href="https://www.notion.so/b40ffc2ac9a544b2aea3d7654162c414" target="_blank" rel="noopener">Untitled</a>                                                                                  12_TDL<br>  <a href="https://www.notion.so/What-is-supervised-learning-09dd42ec845941349a2973e46514e4ed" target="_blank" rel="noopener">What is supervised learning</a>                                   02_SL                          It is the most popular and well established learning paradigm Data from an unknown function that maps an input 𝑥 to an output Goal: learn a good approximation of 𝑓 Classification if 𝑡 is discrete Regression if 𝑡 is continuous feature→ target Probability estimation if 𝑡 is a probability<br>  <a href="https://www.notion.so/When-to-apply-supervised-learning-9368d979e9434d5a88a4012ae29f986e" target="_blank" rel="noopener">When to apply supervised learning?</a>                      02_SL                          when human cannot perform the task When human can perform the task but cannot explain how When the task changes over time user-specific<br>  <a href="https://www.notion.so/overview-eebb4b1f277742e5b5ae42d1088b1645" target="_blank" rel="noopener">overview</a>                                                                         02_SL                          Define <strong>a loss function L</strong> Choose the<strong>hypothesis space H</strong> Find in H an approximation <strong>h of 𝑓 that minimizes L</strong><br>  <a href="https://www.notion.so/Elements-f4b15ce41a3b454ba85aa9ba88a82b1b" target="_blank" rel="noopener">Elements</a>                                                                         02_SL                          Representation → Model Evaluation → Model selection Optimization →<br>  <a href="https://www.notion.so/Optimization-aad6ba52f7354e8ebf69c8af318a6922" target="_blank" rel="noopener">Optimization</a>                                                                 02_SL                          Combinatorial optimization e.g.: Greedy search ❑ Convex optimization e.g.: Gradient descent ❑ Constrained optimization e.g.: Linear programming<br>  <a href="https://www.notion.so/Parametric-vs-Nonparametric-2f3dbd65c77d4ee1aa8dec7736320f92" target="_blank" rel="noopener">Parametric vs Nonparametric</a>                                   02_SL                          <strong>Parametric:**</strong>fixed and finite number of parameters** <strong>Nonparametric:</strong> <strong>the number of parameters depends on the training set</strong><br>  <a href="https://www.notion.so/Frequentist-vs-Bayesian-acf204d158654b37b936061b62e75c44" target="_blank" rel="noopener">Frequentist vs Bayesian</a>                                           02_SL                          Frequentist: use probabilities to model <strong>the sampling process</strong>Bayesian: use probability <strong>to model uncertainty about the estimate</strong><br>  <a href="https://www.notion.so/Linear-Regression-e2ff69a013c14ec68159dc22f804500a" target="_blank" rel="noopener">Linear Regression</a>                                                       03_LR<br>  <a href="https://www.notion.so/Least-Squares-924bcbc0f5af41b7a9101cfbd911c42c" target="_blank" rel="noopener">Least Squares</a>                                                               03_LR<br>  <a href="https://www.notion.so/Regularization-46f5c75c2edd40f38218fdc471676576" target="_blank" rel="noopener">Regularization</a>                                                             03_LR<br>  <a href="https://www.notion.so/Least-Squares-and-Maximum-Likelihood-d557dd03f5104c5083ed1ec12cd515d3" target="_blank" rel="noopener">Least Squares and Maximum Likelihood</a>                 03_LR<br>  <a href="https://www.notion.so/Linear-Classification-62efd37834f04330aca9d0e652bd16de" target="_blank" rel="noopener">Linear Classification</a>                                               04_LC                          Learn, from a dataset 𝒟, an approximation of function 𝑓 𝑥 that maps input 𝑥 to a discrete class*𝐶</em> (with k = 1,…,𝐾)<br>  <a href="https://www.notion.so/Multi-class-904a5fa9f4074fd79434119398440aad" target="_blank" rel="noopener">Multi-class</a>                                                                   04_LC                          In a multi-class problem we have K classes ❑ One-versus-the-rest approach uses K-1 binary cassifiers (i.e., that solve a two-class problem) each classifier discriminates 𝐶 and not 𝐶 regions ambiguity: region mapped to several classes ❑ One-versus-one approach uses K(K-1)/2 class binary classifiers each classifier discriminates between 𝐶 and 𝐶 𝑖𝑖 similary ambiguity of previous approach<br>  <a href="https://www.notion.so/hypothesis-space-5925fe181aa349258e514e2bda28f310" target="_blank" rel="noopener">hypothesis space</a>                                                         06_LearningTheory              A hypothesis h is consistent with a training dataset 𝒟 of the concept c if and only if h(x) = c(x) for each training sample in 𝒟<br>  <a href="https://www.notion.so/VC-Dimension-36bd603bcd504f3e8ba0ee0a2b08f775" target="_blank" rel="noopener">VC Dimension</a>                                                                 06_LearningTheory              VC Dimension <strong>We define a dichotomy of a set S of instances as a partition of S into two disjoint subsets, i.e., labeling each instance in S as positive or negative</strong> ❑ We say that a set of instances S is shattered by hypothesis space H if and only if for every dichotomy of S there exists some hypothesis in H consistent with this dichotomy ❑ The Vapnik-Chervonenkis dimension, VC(H), of hypothesis space H over instance space X, is the largest finite subset of X shattered by H<br>  <a href="https://www.notion.so/Kernel-Methods-a210af678264416a932ae7985c99869c" target="_blank" rel="noopener">Kernel Methods</a>                                                             07_KernalMethods               Kernel methods allow to make<strong>linear models</strong> work in nonlinear settings by mapping data to<strong>higher dimensions</strong>where it exhibits linear patterns<br>  <a href="https://www.notion.so/Kernel-in-1d-example-b36bf58eaf1b4f409891e79f41dbd2a5" target="_blank" rel="noopener">Kernel in 1d example</a>                                                 07_KernalMethods               linear separable<br>  <a href="https://www.notion.so/Kernel-Functions-6d5e1651cd4542d283168c388fba4dbf" target="_blank" rel="noopener">Kernel Functions</a>                                                         07_KernalMethods               The kernel function is defined as the <strong>scalar product</strong> between the feature vectors of two data samples: Kernel function is <strong>symmetric</strong>:𝑘x,x′ =𝑘x′,x<br>  <a href="https://www.notion.so/sample-based-methods-3d82183a9c204166b78b5eda8834892c" target="_blank" rel="noopener">sample-based methods</a>                                                 11_MonteCarlo                  With Dynamic Programming we are able to find the<strong>optimal value functio</strong>n and the <strong>corresponding optimal policy</strong><br>  <a href="https://www.notion.so/First-Visit-Evey-Visit-7f417b020d144649b1cf9d5392463209" target="_blank" rel="noopener">First-Visit &amp; Evey-Visit</a>                                           11_MonteCarlo                  Diff<br>  <a href="https://www.notion.so/Prediction-Control-9f854c78f30e455fa0a207b0ba00bced" target="_blank" rel="noopener">Prediction &amp; Control</a>                                                   11_MonteCarlo                  Diff <strong>Prediction:</strong> is to based on fixed policy to find maximize the estimation value of cumulated sum value. The input involves the policy Pi and MDP formulation. The output is the v_pi and q_pi <strong>Control:</strong> is to find be policy to achieve the goal, the policy is not fixed. The input is MDP description, and the output is the q_pi, V_pi, and <strong>Pi *</strong>(<strong>the optimal policy</strong>)<br>  <a href="https://www.notion.so/On-Policy-Off-Policy-cbff720ea95541fda85d052e53efc556" target="_blank" rel="noopener">On-Policy &amp; Off-Policy</a>                                               11_MonteCarlo                  Diff policy iteration → how to get the <strong>Pi</strong>value?<br>  <a href="https://www.notion.so/MC-Prediction-and-Control-028a28b1e1c24600bbe2250efa6e9fc4" target="_blank" rel="noopener">MC (Prediction and Control)</a>                                     11_MonteCarlo                  Monte Carlo<br>  <a href="https://www.notion.so/diff-between-DP-and-MC-07eacdfd293346f1a9a340476ae81822" target="_blank" rel="noopener">diff between DP and MC</a>                                             11_MonteCarlo                  ??<br>  <a href="https://www.notion.so/Valid-Kernel-5ed769ce2ee344c6ae0319ef3a597163" target="_blank" rel="noopener">Valid Kernel</a>                                                                 07_KernalMethods               From the <strong>Mercers theorem</strong>, any continuous, symmetric, positive semi-definite kernel function can be expressed as a dot product in a high-dimensional space.<br>  <a href="https://www.notion.so/Rigid-Regression-Logistic-regression-Lasso-f1eef5f775f74419a02d345786bb2fed" target="_blank" rel="noopener">Rigid Regression, Logistic regression, Lasso</a>   Example                         What is it?<br>  <a href="https://www.notion.so/SVC-sample-44de0a876e5c4f2c88606280897409e7" target="_blank" rel="noopener">SVC sample</a>                                                                     Example                         10^num_paramter, e.g. 100 = 10ˆ2<br>  <a href="https://www.notion.so/VC-dimension-2cd523747c714ca299843164c19bc01e" target="_blank" rel="noopener">VC dimension</a>                                                                 Example<br>  <a href="https://www.notion.so/GMM-583bdc9df8cf496d94b1ca2d855fdfbf" target="_blank" rel="noopener">GMM</a>                                                                                   Example                         GMM considers differently each dimension, <strong>by considering a generic covariance matrix</strong> while estimating the Gaussian distributions.<br>  <a href="https://www.notion.so/PARAMETRIC-NON-PARAMETRIC-bf8c4ed904ed43a5a4d07845e7b374be" target="_blank" rel="noopener">PARAMETRIC/NON–PARAMETRIC</a>                                       Example                         the difference<br>  <a href="https://www.notion.so/Q-learning-f4af7fdfe3934c0bbb2840703f550e9a" target="_blank" rel="noopener">Q-learning</a>                                                                     Example                         what is q learning?</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/21/pcsoraltest/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/21/pcsoraltest/" class="post-title-link" itemprop="url">Can computers write meaningful music?</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-21 15:58:42 / Modified: 14:18:38" itemprop="dateCreated datePublished" datetime="2020-06-21T15:58:42Z">2020-06-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>This semester I wrote a thesis for philosophy issue in Computer Science. At first, this was just a try in preparing for a master thesis next year. After following some lectures included in this course, I started to find more interest in writing a thesis in this field. My title is “Can computers write meaningful music?”, with the related fields of Computer Music, Music Composition, Computational Creativity, and Philosophy Issues in CS.</p>
<p>I am writing this note for the discussion session on next Tuesday.</p>
<h2 id="Keypoints"><a href="#Keypoints" class="headerlink" title="Keypoints"></a>Keypoints</h2><ul>
<li><p>Definition related: computers / computational creativity / programs to solve problems in music composition</p>
</li>
<li><p>Focus: Are they able to create music? Do they have the ability to create Meaningful muisic? Can computers have creativity?</p>
</li>
<li><p>Discussion in the Argument:</p>
<ul>
<li><p>The definition of program → Arg 1.  programs can do things beyond human expectations and limits{ <strong>Vague Problem</strong>, <strong>Unpredictable Answer</strong>, }</p>
</li>
<li><p>the definition of computational creativity</p>
</li>
<li><p><a href="https://plato.stanford.edu" target="_blank" rel="noopener">Stanford Encyclopedia of Philosophy</a></p>
</li>
<li><p>Judge the result, how human bias influence the result → Arg 2. Judging the composition itself { <strong>Definition of Creativity, Human Bias</strong> }</p>
</li>
<li><p>The essence of meaning {<strong>Expression of Emotions, Innovation Power</strong>}</p>
</li>
<li><p>Final conclusion</p>
</li>
</ul>
</li>
</ul>
<h2 id="My-reference"><a href="#My-reference" class="headerlink" title="My reference"></a>My reference</h2><ul>
<li>Literature Resource ( as supporting material)</li>
</ul>
<ol>
<li><p>[1]  Gérard Assayag et al. “Interaction with machine improvisation”. In:The Structure ofStyle. Springer, 2010, pp. 219–245.doi:10.1007/978-3-642-12337-5_10.</p>
</li>
<li><p>[2]  Simon Colton. “Creativity Versus the Perception of Creativity in Computational Sys-tems”. In:AAAI spring symposium: creative intelligent systems. Vol. 8. 2008.</p>
</li>
<li><p>[3]  Michael Edwards. “Algorithmic composition: computational thinking in music”. In:Communications of the ACM54.7 (2011), pp. 58–67.doi:10.1145/1965724.1965742.</p>
</li>
<li><p>[4]  Jose D Fernández and Francisco Vico. “AI methods in algorithmic composition: A com-prehensive survey”. In:Journal of Artificial Intelligence Research48 (2013), pp. 513–582.doi:10.1613/jair.3908.</p>
</li>
<li><p>[5]  Aaron Hertzmann. “Can computers create art?” In:Arts. Vol. 7. 2. MultidisciplinaryDigital Publishing Institute. 2018, p. 18.doi:10.3390/arts7020018.</p>
</li>
<li><p>[6]  MD Louis L. Lunsky. “Contemporary Approaches to Creative Thinking”. In:Arch In-tern Med112.2 (1963), pp. 300–301.doi:10.1001/archinte.1963.03860020198043.</p>
</li>
<li><p>[7]  Ramon Lopez de Mantaras and Josep Lluis Arcos. “AI and Music: From Compositionto Expressive Performance”. In:AI Magazine23.3 (2002), p. 43.</p>
</li>
<li><p>[8]  Marvin Minsky. “Why programming is a good medium for expressing poorly understoodand sloppily formulated ideas”. In: 1967, pp. 120–125.doi:10.1145/1094855.1094860.</p>
</li>
<li><p>[9]  David C Moffat and Martin Kelly. “An investigation into people’s bias against compu-tational creativity in music composition”. In:Assessment13.11 (2006).</p>
</li>
</ol>
<ul>
<li>Examples used:?</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/17/review/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/17/review/" class="post-title-link" itemprop="url">CMLS_Review Outline</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-17 21:22:21 / Modified: 19:22:21" itemprop="dateCreated datePublished" datetime="2020-06-17T21:22:21Z">2020-06-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-Music-Information-Retrieval"><a href="#1-Music-Information-Retrieval" class="headerlink" title="1. Music Information Retrieval"></a>1. Music Information Retrieval</h2><p><strong>FILE: 1A. INTRODUCTION TO SOUND CLASSIFICATION</strong></p>
<ul>
<li>Slide 6 to 12</li>
<li>Slides 14 to 17</li>
<li>Slides 20 to 41</li>
<li>Slides 44 to 47</li>
<li>Slides 50 to 86</li>
<li>Slides 87 to 92</li>
</ul>
<p><a href="https://www.notion.so/e9108aec57064f8f9818b6a69416b9ea" target="_blank" rel="noopener">Classification</a></p>
<h2 id="2-Computer-Music-Systems-and-Plugins"><a href="#2-Computer-Music-Systems-and-Plugins" class="headerlink" title="2. Computer Music Systems and Plugins"></a>2. Computer Music Systems and Plugins</h2><p>FILE: 2A. INTRODUCTION TO COMPUTER MUSIC ARCHITECTURES</p>
<p>• Slide 1 to 29</p>
<p>FILE: 2B.JUCE AS A PLATFORM FOR AUDIO PLUGINS</p>
<p>• Slides 4 and 5<br>• Slides 7 to 11</p>
<p><a href="https://www.notion.so/d449ac2e90e449d2951fe4cd003c9909" target="_blank" rel="noopener">JUCE</a></p>
<h2 id="3-SuperCollider"><a href="#3-SuperCollider" class="headerlink" title="3. SuperCollider"></a>3. SuperCollider</h2><p>FILE: C.1 THE SUPERCOLLLIDER ECOSYSTEM</p>
<p>• Slides 3 to 48</p>
<p><a href="https://www.notion.so/2532c25c27f24b2a9ecd88dad7e87a28" target="_blank" rel="noopener">SuperCollider</a></p>
<p>FILE: C.2 SUPERCOLLIDER AS A COMPUTER MUSIC LANGUAGE</p>
<p>• Slides 3 to 40<br>• Slides 47 to 68</p>
<p><a href="https://www.notion.so/e9d776e36ef24b89ba8a3270bc2e5b5d" target="_blank" rel="noopener">C.2 SuperCollider</a></p>
<h2 id="4-Music-Interaction"><a href="#4-Music-Interaction" class="headerlink" title="4. Music Interaction"></a>4. Music Interaction</h2><p><strong>FILE: D.1 INTRODUCTION TO MUSIC INTERACTION</strong></p>
<p>• Slides 3 to 5</p>
<p><a href="https://www.notion.so/f520cdbe047d42fda278c72937850ecf" target="_blank" rel="noopener">Intro to Music Interaction</a></p>
<p><strong>FILE: D.2 MUSIC TRANSMISSION PROTOCOLS</strong></p>
<p>• Slides 1 to 24<br>• Slides 27 to 36</p>
<p>• Slides 37 to 48</p>
<p><a href="https://www.notion.so/9fdc36d21b9a4f0f985b088591dd6f91" target="_blank" rel="noopener">Music Transmission</a></p>
<p><strong>FILE: D.3 USING MUSIC TRANSMISSION PROTOCOLS IN DIFFERENT CM ENVIRONMENTS</strong></p>
<p>• Slides 1 to 53</p>
<p><a href="https://www.notion.so/d9c8fc20cc07472dbbf66324d34bad41" target="_blank" rel="noopener">Using music transmission</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/11/timer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/11/timer/" class="post-title-link" itemprop="url">timer</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-06-11 12:37:28 / Modified: 10:50:27" itemprop="dateCreated datePublished" datetime="2020-06-11T12:37:28Z">2020-06-11</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Today my friend come to lunch, lunch is prepared in the oven and I don’t want to move to take the timer.<br>Here is a way to set a timer on OSX.</p>
<p>‘’’<br>setalarm() {<br>    sleep $(echo “$1 * 60” | bc)<br>    say “Lunch Time”<br>}<br>setalarm 1<br>‘’’</p>
<h3 id="What’s-interesting"><a href="#What’s-interesting" class="headerlink" title="What’s interesting"></a>What’s interesting</h3><ul>
<li>“say” command </li>
<li>say -v “voice name” “text to say”</li>
<li>voice name includes: Femal, Male and Novelty Voice, like “Cellos”, “Bad News”, “Pipe Organ”</li>
<li>output the recording: say -v “Cellos” “Lalalalalalalalala” -o save.aiff</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/28/sp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/28/sp/" class="post-title-link" itemprop="url">SuperCollider & Processing</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-28 21:48:38" itemprop="dateCreated datePublished" datetime="2020-05-28T21:48:38Z">2020-05-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-06-07 13:10:31" itemprop="dateModified" datetime="2020-06-07T13:10:31Z">2020-06-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Ps: supercollider 居然是 Beatles Paul Mccartney 的儿子在 1996 年开发的！</p>
<h2 id="What-is-supercollider"><a href="#What-is-supercollider" class="headerlink" title="What is supercollider"></a>What is supercollider</h2><ol>
<li>A platform for audio synthesis and algorithmic composition</li>
<li>Users: musicians, artists, and researchers working with sound</li>
<li>Three major components<ul>
<li>scsynth: <ul>
<li>a real time audio server</li>
<li>core</li>
<li>400 + unit generators(“UGens”) of analysis, synthesis, and processing</li>
<li>known and unknown audio techniques</li>
<li>additive and subtractive synthesis, FM, granular synthesis, FFT, and physical modeling</li>
</ul>
</li>
</ul>
</li>
</ol>
<pre><code>* sclang: language
    - controls scsynth via Open Sound Control
    - algorithmic composition and sequencing
* scide: ide</code></pre><h2 id="Systems-interfacing-with-SC"><a href="#Systems-interfacing-with-SC" class="headerlink" title="Systems interfacing with SC"></a>Systems interfacing with SC</h2><ol>
<li>send osc message from shell</li>
<li>client using sc server<br> Scheme, Smalltalk, Python, Processing, Perl, Java…</li>
</ol>
<h2 id="Processing"><a href="#Processing" class="headerlink" title="Processing"></a>Processing</h2><h2 id="OSC-Communication"><a href="#OSC-Communication" class="headerlink" title="OSC Communication"></a>OSC Communication</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/22/chineseroom/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/22/chineseroom/" class="post-title-link" itemprop="url">The Chinese Room</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-21 22:30:47 / Modified: 21:13:50" itemprop="dateCreated datePublished" datetime="2020-05-21T22:30:47Z">2020-05-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Key-points"><a href="#Key-points" class="headerlink" title="Key points"></a>Key points</h2><ul>
<li>concept:  producing a behavior which is then interpreted by the user as demonstrating intelligent conversation</li>
<li>infer: without “understanding” (or “intentionality”), we cannot describe what the machine is doing as “thinking” and, since it does not think, it does not have a “mind” in anything like the normal sense of the word. </li>
<li>conclusion: the “strong AI” hypothesis is false.</li>
<li>Strong AI vs. biological naturalism: dk???</li>
</ul>
<h2 id="From-the-definition"><a href="#From-the-definition" class="headerlink" title="From the definition"></a>From the definition</h2><ul>
<li><p>How to understand a totally different thing from the concept?</p>
</li>
<li><p>How can we make computers to understand human emotions and human feelings</p>
</li>
<li><p>Even if a computer can do as human do, think as human thoughts, is it really on the same level of us?</p>
</li>
<li><p>How to learn Chinese from English dictionary?</p>
</li>
<li><p>What is the concept of computer programing?</p>
</li>
<li><p>If computers are set up a goal, we giving them abilities from executing programes, are they actually having to ability to do something, or they are just acting like humans while executing the programs.</p>
</li>
<li><p>If they pass the turing test, then it is human?</p>
</li>
<li><p>Is there real strong Artificial Intelligence?</p>
</li>
<li><p>All the doubts are not limiting the amount of intelligence a machine can display.</p>
</li>
</ul>
<h2 id="Other-Doubts"><a href="#Other-Doubts" class="headerlink" title="Other Doubts"></a>Other Doubts</h2><ul>
<li>What is the Turing test in music composition?</li>
<li>We can not tell which composition is made by human and which is made by machine?</li>
<li>If we find some music piece interesting, is it meaningful?</li>
<li>If we find some human composiiton boring and strange, is it meaningful?</li>
<li>What’s the border line between human composition and computer generated music if you can not tell the difference from listening to the music they made?</li>
<li>The intension, the passion and how much they want to convey through the emotional expression?</li>
<li>Human are social animals, so music is kind of connection? Music shoudl be meaningful in the social way?</li>
<li>What is art? Is it only the pursuit of human? Only human creation?</li>
<li>Artificial intelligence should be a human, able to understand and express emotion, then their works can be recognized as meaningful music.</li>
<li>Every music has its soul?</li>
</ul>
<h2 id="Reading"><a href="#Reading" class="headerlink" title="Reading"></a>Reading</h2><ol>
<li>“Minds, Brains, and Programs”,John Searle</li>
<li><a href="https://en.wikipedia.org/wiki/Chinese_room" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Chinese_room</a></li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/06/interact/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/06/interact/" class="post-title-link" itemprop="url">Music Interaction Design and predictive models</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-05-05 22:57:33 / Modified: 21:04:09" itemprop="dateCreated datePublished" datetime="2020-05-05T22:57:33Z">2020-05-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="0504-Music-Interaction-Design"><a href="#0504-Music-Interaction-Design" class="headerlink" title="0504 Music Interaction Design"></a>0504 Music Interaction Design</h1><h2 id="What-is-interaction-Design"><a href="#What-is-interaction-Design" class="headerlink" title="What is interaction Design?"></a>What is interaction Design?</h2><ul>
<li><p>The practice of designing interactive digital products, environment</p>
</li>
<li><p>Who interact with who?<br>  machine, software,  HCI</p>
</li>
<li><p>Where does interaction design enter in a computer music system?</p>
<ul>
<li>gestures - input device</li>
<li>other IO Device, machine to machine</li>
</ul>
</li>
<li><p>Setup an interaction</p>
<ul>
<li>capture the gesture</li>
<li>mapping system</li>
<li>the transmission of the gestural and musical signals between different devices</li>
<li>Related areas: creative programming, electronics, telecommunication protocols</li>
</ul>
</li>
<li><p>Example of M2M interaction</p>
<ul>
<li>laptop orchestra by Stanford</li>
<li>position, gesture -&gt; music parameters -&gt; centre node -&gt; synthesis -&gt; music system (not a product, just used for this purpose)</li>
<li>IMU Motion Tracker(controller, feedback, flex sensors, connection with osc(?))</li>
<li>leap motion(device)</li>
</ul>
</li>
<li><p>AI for music interaction</p>
<ul>
<li>how if the computer could learn our way to interact with it?</li>
<li>eg. Wekinator, an AI system automatically study (gesture space -&gt; music space)</li>
</ul>
</li>
</ul>
<h2 id="Related-Readings"><a href="#Related-Readings" class="headerlink" title="Related Readings"></a>Related Readings</h2><ol>
<li><p>Deep Predictive Models in Interactive Music, <a href="https://arxiv.org/pdf/1801.10492.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1801.10492.pdf</a></p>
<ul>
<li>how is deep learning involved in music performace</li>
<li>especially digital musical instruments</li>
<li>musical predictions</li>
<li>difference between mapping and modelling<ul>
<li>Mapping refers to connecting the control and sensing components of a musical instrument to parameters in the sound synthesis component </li>
<li>Modelling refers to capturing a representation of a musical process</li>
</ul>
</li>
</ul>
</li>
<li><p>How to generate music?</p>
<ul>
<li>ANN -&gt; RNN -&gt; LSTM : improved (to learn distant dependencies)</li>
<li>RNNs with LSTM cells were later used by Eck and Schmidhuber to generate blues music</li>
<li>generate music using Markov models to generate the emission probabilities of future notes based on those preceding</li>
<li>Bach music, polyphonic chorales of J. S. Bach have also been modelled by RNN</li>
<li>difference in these models ???</li>
<li>learn much about the temporal structure of music, and how melodies and harmonies can be constructed</li>
<li>Simon and Oore’s Performance RNN: goes further by generating dynamics and rhythmic expression, or rubato, simultaneously with polyphonic music.</li>
<li>WaveNet: producing samples</li>
</ul>
</li>
<li><p>Predictive models: instrument-level -&gt; performer-level -&gt; ensemble-level</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/05/super2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/05/super2/" class="post-title-link" itemprop="url">Intro to Supervised Learning Notes(2)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-05 10:01:33" itemprop="dateCreated datePublished" datetime="2020-04-05T10:01:33Z">2020-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-11 21:48:57" itemprop="dateModified" datetime="2020-04-11T21:48:57Z">2020-04-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="1-High-dimensional-Feature"><a href="#1-High-dimensional-Feature" class="headerlink" title="1. High dimensional Feature"></a>1. High dimensional Feature</h3><ul>
<li>what is the difference between low dimensional feature and high dimensional feature</li>
<li>x = [x1,x2,…,xn] -&gt; y</li>
<li>infinite dimensional features</li>
<li>select features based on the data</li>
</ul>
<h3 id="2-Regression-vs-Classification"><a href="#2-Regression-vs-Classification" class="headerlink" title="2. Regression vs Classification"></a>2. Regression vs Classification</h3><ul>
<li>regression: if y is continuous variable,<br>  e.g., price prediction</li>
<li>classification: if the label is a discrete variable<br>  e.g., the task of predicting the types of residence</li>
</ul>
<h3 id="3-Supervised-learning-in-computer-science"><a href="#3-Supervised-learning-in-computer-science" class="headerlink" title="3. Supervised learning in computer science"></a>3. Supervised learning in computer science</h3><ul>
<li>Image Classification: x = raw pixels of the picture, and y = label</li>
<li>Natural language processing</li>
</ul>
<h3 id="4-unsupervised-learning"><a href="#4-unsupervised-learning" class="headerlink" title="4. unsupervised learning"></a>4. unsupervised learning</h3><ul>
<li>only have data without labels</li>
<li>goal is to find interesting structure in the data</li>
</ul>
<h3 id="5-Clustering-amp-Other"><a href="#5-Clustering-amp-Other" class="headerlink" title="5. Clustering &amp; Other"></a>5. Clustering &amp; Other</h3><ul>
<li>k-mean clustering, mixture of Gaussians</li>
<li>clustering genes</li>
<li>principal component analysis (tools used in<br>LSA)</li>
<li>word emeddings(Represent words by vectors),eg Word2vec</li>
<li>clustering words with similar meanings</li>
</ul>
<h3 id="6-Reinforcement-Learning"><a href="#6-Reinforcement-Learning" class="headerlink" title="6. Reinforcement Learning"></a>6. Reinforcement Learning</h3><ul>
<li>learning to walk to the right</li>
<li>the algorithms can collect data interactively</li>
<li>method: try the strategy and collect feedbacks(Data Collections &amp; Training),to improve the strategy based on the feedbacks</li>
</ul>
<h2 id="SL-Setup"><a href="#SL-Setup" class="headerlink" title="SL:Setup"></a>SL:Setup</h2><ul>
<li>Linear Regression</li>
<li>x -&gt; y</li>
<li>gradient descent</li>
</ul>
<h2 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h2><h2 id="Probability"><a href="#Probability" class="headerlink" title="Probability"></a>Probability</h2><h2 id="Gaussian-Discriminant-Analysis"><a href="#Gaussian-Discriminant-Analysis" class="headerlink" title="Gaussian Discriminant Analysis"></a>Gaussian Discriminant Analysis</h2><h2 id="Support-Vector-Machines-Kernels"><a href="#Support-Vector-Machines-Kernels" class="headerlink" title="Support Vector Machines. Kernels."></a>Support Vector Machines. Kernels.</h2><h2 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h2><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="http://cs229.stanford.edu/notes2020spring/lecture1_slide.pdf" target="_blank" rel="noopener">http://cs229.stanford.edu/notes2020spring/lecture1_slide.pdf</a></li>
<li><a href="http://cs229.stanford.edu/notes2020spring/cs229-notes1.pdf" target="_blank" rel="noopener">http://cs229.stanford.edu/notes2020spring/cs229-notes1.pdf</a></li>
<li>CS224N/CS231N</li>
<li>Identifying Regulatory Mechanisms using Individual Variation Reveals Key Role for Chromatin Modification.</li>
<li>Luo-Xu-Li-Tian-Darrell-M.’18</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/04/super/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/04/super/" class="post-title-link" itemprop="url">Intro to Supervised Learning Notes</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-04 12:13:42" itemprop="dateCreated datePublished" datetime="2020-04-04T12:13:42Z">2020-04-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-11 21:44:30" itemprop="dateModified" datetime="2020-04-11T21:44:30Z">2020-04-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index"><span itemprop="name">Notes</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-What-is-Machine-Learning"><a href="#1-What-is-Machine-Learning" class="headerlink" title="1. What is Machine Learning?"></a>1. What is Machine Learning?</h2><p>Two definitions of Machine Learning are offered. </p>
<ul>
<li><p>Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition.</p>
</li>
<li><p>Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”</p>
</li>
<li><p>Example: playing checkers.<br>E = the experience of playing many games of checkers<br>T = the task of playing checkers.<br>P = <em>the probability</em> that the program will win the next game.</p>
</li>
<li><p>In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning and Unsupervised learning.</p>
</li>
<li><p>Except from supervised learning and unsupervised, there are also Reinforcement learning, recommender systems.</p>
</li>
</ul>
<h3 id="用机器模拟人脑"><a href="#用机器模拟人脑" class="headerlink" title="用机器模拟人脑"></a>用机器模拟人脑</h3><ul>
<li>人可以描述问题，但不知道如何显式地解决问题</li>
<li>让机器得到输入和输出，寻找解决途径</li>
<li>计算机科学，可以应用在工业和基础科学上。{自动直升机，手写识别，自然语言，机器视觉，推荐算法}</li>
<li>需要足够多的数据</li>
</ul>
<h3 id="不同类型的学习算法"><a href="#不同类型的学习算法" class="headerlink" title="不同类型的学习算法"></a>不同类型的学习算法</h3><ul>
<li>作为 Tools/methods, 选择哪一种方法要看得到的数据情况（离散的数据？连续的数据）和要解决的问题（预测？分类？）</li>
<li>监督学习</li>
<li>无监督学习</li>
<li>强化学习</li>
</ul>
<h3 id="选择的问题"><a href="#选择的问题" class="headerlink" title="选择的问题"></a>选择的问题</h3><ul>
<li>需要理解算法本身，我们才能根据具体的实践问题，决定采用哪一种方法（最节省时间和精力）建立系统</li>
<li>机器可以有多种方法达到目标，但是哪一种是最优的</li>
</ul>
<h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><ul>
<li>Classification: Discrete valued</li>
<li>Classification(discrete) CF Regression(Continus)</li>
</ul>
<h2 id="2-What-is-supervised-learning"><a href="#2-What-is-supervised-learning" class="headerlink" title="2. What is supervised learning"></a>2. What is supervised learning</h2><ul>
<li>most important one in learning paradigm</li>
<li>an unknown function f that maps an input 𝑥 to an output  t: D = {&lt;x, t&gt;}</li>
</ul>
<h3 id="Goal-of-SL"><a href="#Goal-of-SL" class="headerlink" title="Goal of SL"></a>Goal of SL</h3><ul>
<li>Goal: is to learn a good approximation of 𝑓</li>
<li>Input variables 𝑥 are usually called features or attributes</li>
<li>Output variables 𝑡 are also called targets or labels</li>
</ul>
<h3 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h3><p>Classification if 𝑡 is discrete<br>Regression if 𝑡 is continuous<br>Probability estimation if 𝑡 is a probability </p>
<h3 id="Elements-in-Supervised-Learning"><a href="#Elements-in-Supervised-Learning" class="headerlink" title="Elements in Supervised Learning"></a>Elements in Supervised Learning</h3><ol>
<li>Representation<ul>
<li>Consist {linear models, instance-based, decision trees, set of rules, graphical models, neural networks, Gaussian Processes, Support vector machines, Model ensembles }</li>
</ul>
</li>
<li>Evaluation<ul>
<li>{Accuracy, precision and recall, squared error, Likelihood,<br>Posterior probability, Cost/Utility, Margin, Entropy, KL divergence}</li>
</ul>
</li>
<li>Optimization<ul>
<li>{ Combinatorial optimisation e.g.: Greedy search<br>Convex optimisation e.g.: Gradient descent<br>Constrained optimisation e.g.: Linear programming }</li>
</ul>
</li>
</ol>
<h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><ol>
<li>Training Set</li>
<li>Learning Algorithms</li>
<li>Function h(hypothesis) {Input: size of a house -&gt; h -&gt; Output:estimated price}</li>
</ol>
<h2 id="3-Unsupervised-Learning"><a href="#3-Unsupervised-Learning" class="headerlink" title="3. Unsupervised Learning"></a>3. Unsupervised Learning</h2><ul>
<li>Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don’t necessarily know the effect of the variables.</li>
<li>We can derive this structure by clustering the data based on relationships among the variables in the data.</li>
<li>With unsupervised learning there is no feedback based on the prediction results.</li>
</ul>
<h3 id="Example"><a href="#Example" class="headerlink" title="Example:"></a>Example:</h3><ul>
<li><p>Clustering: Take a collection of 1,000,000 different genes, and find a way to automatically group these genes into groups that are somehow similar or related by different variables, such as lifespan, location, roles, and so on.</p>
</li>
<li><p>Non-clustering: The “Cocktail Party Algorithm”, allows you to find structure in a chaotic environment. (i.e. identifying individual voices and music from a mesh of sounds at a cocktail party).</p>
</li>
</ul>
<h2 id="4-Model-and-Cost-Functions"><a href="#4-Model-and-Cost-Functions" class="headerlink" title="4. Model and Cost Functions"></a>4. Model and Cost Functions</h2><ol>
<li><p>Linear Regression:</p>
<ul>
<li>supervised learning:gives the “right answer” to the</li>
<li>Regression : predict real-valued output</li>
<li><ul>
<li>Classification: get discrete-valued output {eg:0,1}</li>
</ul>
</li>
</ul>
</li>
<li><p>Traning Models</p>
<ul>
<li>number of training examples</li>
<li>input variables/ features</li>
<li>output variables/ target </li>
</ul>
</li>
<li><p>Workflow</p>
<ul>
<li>Training Set -&gt;Learning Algorithms -&gt;</li>
</ul>
</li>
</ol>
<p>…</p>
<h2 id="5-Linear-Regression"><a href="#5-Linear-Regression" class="headerlink" title="5. Linear Regression"></a>5. Linear Regression</h2><h2 id="6-Linear-Classification"><a href="#6-Linear-Classification" class="headerlink" title="6. Linear Classification"></a>6. Linear Classification</h2><h2 id="7-Model-Evaluation-Selection-Ensembles"><a href="#7-Model-Evaluation-Selection-Ensembles" class="headerlink" title="7. Model Evaluation, Selection Ensembles"></a>7. Model Evaluation, Selection Ensembles</h2><h3 id="Bias-Variance"><a href="#Bias-Variance" class="headerlink" title="Bias Variance"></a>Bias Variance</h3><ol>
<li>The Bias-Variance is a framework to analyze the performance of models</li>
<li>Definition:<ul>
<li>data </li>
<li>model</li>
<li>performance</li>
<li>Thus we can decompose the expectected square error as:</li>
</ul>
</li>
<li>Model Variance,</li>
<li>Case Study: Bias Variance for K-NN</li>
</ol>
<p>我们希望模型准确，误差尽可能的小。</p>
<p>…….</p>
<h2 id="8-Reference"><a href="#8-Reference" class="headerlink" title="8. Reference"></a>8. Reference</h2><ol>
<li>Material of prof. Marcello Restelli</li>
<li>Pattern Recognition and Machine Learning, Bishop [PRML]</li>
<li>Elements of Statistical Learning, Hastie et al. [ESL]</li>
<li>Introduction to Statistical Learning, James et al. [ISL]</li>
<li>The Lack of A Priori Distinctions Between Learning Algorithms, Wolpert, 1996</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/03/pj0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avat.JPG">
      <meta itemprop="name" content="Yilin">
      <meta itemprop="description" content="Thoughts. Notes.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Parking Site">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/03/pj0/" class="post-title-link" itemprop="url">Boston housing Predictor</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-03 15:42:53" itemprop="dateCreated datePublished" datetime="2020-04-03T15:42:53Z">2020-04-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-07 12:25:11" itemprop="dateModified" datetime="2020-04-07T12:25:11Z">2020-04-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Projects/" itemprop="url" rel="index"><span itemprop="name">Projects</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>机器学习实验项目_波士顿房价预测</p>
<h2 id="0-项目背景"><a href="#0-项目背景" class="headerlink" title="0. 项目背景"></a>0. 项目背景</h2><p>这是一个几年之前的机器学习练习项目。数据来源是UCI的机器学习知识库数据集。该数据从1978年开始，共506个数据点，涵盖了马萨诸塞州波士顿郊区的房屋信息数据。</p>
<p>在此项目中，我会使用这些数据训练并测试一个可用的预测模型，并对模型的性能和预测能力进行测试。训练好的模型可以对房屋的价值进行预测，对某些工作中，应用这个模型可以帮助他们了解房屋的潜在价值，是非常实用的。</p>
<p>从学习的角度来看，做这个项目则是可以初步了解机器学习的实践方法，了解如何处理数据，并熟悉 python 和 sklearn在项目中的使用。</p>
<blockquote>
<p><strong>提示：</strong>Code 和 Markdown 区域可通过 <strong>Shift + Enter</strong> 快捷键运行。此外，Markdown可以通过双击进入编辑模式。</p>
</blockquote>
<hr>
<h2 id="1-导入数据"><a href="#1-导入数据" class="headerlink" title="1. 导入数据"></a>1. 导入数据</h2><p>本项目的数据集来自<a href="https://archive.ics.uci.edu/ml/datasets.html" target="_blank" rel="noopener">UCI机器学习知识库(数据集已下线)</a>。<br>可以看到，波士顿房屋这些数据于1978年开始统计，共506个数据点，涵盖了麻省波士顿不同郊区房屋14种特征的信息。<br>在此，首先我将针对本项目对原始数据集做以下处理：观察数据 -&gt; 移除异常值 -&gt; 思考哪些是和目标相关的特征。<br>具体处理如下：</p>
<ul>
<li>有16个<code>&#39;MEDV&#39;</code> 值为50.0的数据点被移除。 因为这些数据点包含遗失或者不明确的数值。</li>
<li>有1个数据点的 <code>&#39;RM&#39;</code> 值为8.78. 这是一个异常值，已经被移除。</li>
<li>对于本项目，房屋的<code>&#39;RM&#39;</code>， <code>&#39;LSTAT&#39;</code>，<code>&#39;PTRATIO&#39;</code>以及<code>&#39;MEDV&#39;</code>特征是必要的，其余不相关特征已经被移除。</li>
<li><code>&#39;MEDV&#39;</code>特征的值已经过必要的数学转换，可以反映35年来市场的通货膨胀效应。</li>
</ul>
<p>运行下面区域的代码后，我就可以载入波士顿房屋数据集，以及一些此项目所需的Python库。<br>我会从 csv 文件中读取到需要的数值，如果成功返回数据集的大小，则表示数据集已载入成功。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> visuals <span class="keyword">as</span> vs <span class="comment"># import supplement</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># check Python version </span></span><br><span class="line"><span class="keyword">from</span> sys <span class="keyword">import</span> version_info</span><br><span class="line"><span class="keyword">if</span> version_info.major != <span class="number">2</span> <span class="keyword">and</span> version_info.minor != <span class="number">7</span>:</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'Please use Python 2.7'</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># show result in notebook</span></span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 载入波士顿房屋的数据集</span></span><br><span class="line">data = pd.read_csv(<span class="string">'housing.csv'</span>)</span><br><span class="line">prices = data[<span class="string">'MEDV'</span>]</span><br><span class="line">features = data.drop(<span class="string">'MEDV'</span>, axis = <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 完成</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Boston housing dataset has &#123;&#125; data points with &#123;&#125; variables each."</span>.format(*data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>Boston housing dataset has 489 data points with 4 variables each.</code></pre><hr>
<h2 id="2-分析数据"><a href="#2-分析数据" class="headerlink" title="2. 分析数据"></a>2. 分析数据</h2><p>我需要继续观察目前得到的数据，以便在后续阶段能够理解对数据进行分析后得到的结果或对结果进行分析。</p>
<p>由于我的最终目标是将实现一个表现良好的房屋价值预估的模型，所以我依然需要把完整的数据集分成<strong>feature</strong>和<strong>target</strong>。</p>
<ul>
<li><strong>特征</strong>： <code>&#39;RM&#39;</code>， <code>&#39;LSTAT&#39;</code>，和 <code>&#39;PTRATIO&#39;</code></li>
<li><strong>目标变量</strong>：<code>&#39;MEDV&#39;</code>，是我希望预测的变量。</li>
</ul>
<p>我用 <code>features</code>和<code>prices</code>两个变量进行存储。</p>
<h3 id="2-1-基础统计运算"><a href="#2-1-基础统计运算" class="headerlink" title="2.1 基础统计运算"></a>2.1 基础统计运算</h3><p>我导入了<code>numpy</code> 执行计算。这些统计数据对于分析模型的预测结果非常重要的。</p>
<ul>
<li>计算<code>prices</code>中的<code>&#39;MEDV&#39;</code>的最小值、最大值、均值、中值和标准差；</li>
<li>将运算结果储存在相应的变量中。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#目标：计算价值的最小值</span></span><br><span class="line">minimum_price = np.min(prices)</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标：计算价值的最大值</span></span><br><span class="line">maximum_price = np.max(prices)</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标：计算价值的平均值</span></span><br><span class="line">mean_price = np.mean(prices)</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标：计算价值的中值</span></span><br><span class="line">median_price = np.median(prices)</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标：计算价值的标准差</span></span><br><span class="line">std_price = np.std(prices)</span><br><span class="line"></span><br><span class="line"><span class="comment">#目标：输出计算的结果</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Statistics for Boston housing dataset:\n"</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Minimum price: $&#123;:,.2f&#125;"</span>.format(minimum_price)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Maximum price: $&#123;:,.2f&#125;"</span>.format(maximum_price)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Mean price: $&#123;:,.2f&#125;"</span>.format(mean_price)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Median price $&#123;:,.2f&#125;"</span>.format(median_price)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Standard deviation of prices: $&#123;:,.2f&#125;"</span>.format(std_price)</span><br></pre></td></tr></table></figure>

<pre><code>Statistics for Boston housing dataset:

Minimum price: $105,000.00
Maximum price: $1,024,800.00
Mean price: $454,342.94
Median price $438,900.00
Standard deviation of prices: $165,171.13</code></pre><h3 id="2-2-特征观察"><a href="#2-2-特征观察" class="headerlink" title="2.2 特征观察"></a>2.2 特征观察</h3><p>如前文所述，本项目中我们关注的是其中三个值:<code>&#39;RM&#39;</code>、<code>&#39;LSTAT&#39;</code> 和<code>&#39;PTRATIO&#39;</code>，对每一个数据点:</p>
<ul>
<li><code>&#39;RM&#39;</code> 是该地区中每个房屋的平均房间数量；</li>
<li><code>&#39;LSTAT&#39;</code> 是指该地区有多少百分比的业主属于是低收入阶层（有工作但收入微薄）；</li>
<li><code>&#39;PTRATIO&#39;</code> 是该地区的中学和小学里，学生和老师的数目比（<code>学生/老师</code>）。</li>
</ul>
<p><em>凭直觉，上述三个特征中对每一个来说，你认为增大该特征的数值，<code>&#39;MEDV&#39;</code>的值会是<strong>增大</strong>还是<strong>减小</strong>呢？</em></p>
<ul>
<li>RM 变大，MEDV 越大，因为房间多整体空间更大</li>
<li>LSTAT 越大，MEDV 越小，因为代表着当地经济价值比较低</li>
<li>PTRATIO 越大，MEDV 越低，因为该地区学生多教师少，教育价值降低了</li>
</ul>
<h3 id="2-2-数据分割与重排"><a href="#2-2-数据分割与重排" class="headerlink" title="2.2 数据分割与重排"></a>2.2 数据分割与重排</h3><p>接下来，我需要把波士顿房屋数据集分成训练和测试两个子集。<br>通常在这个过程中，数据也会被重排列，以消除数据集中由于顺序而产生的偏差。</p>
<p>我使用 <code>sklearn.model_selection</code> 中的 <code>train_test_split</code>， 将<code>features</code>和<code>prices</code>的数据都分成用于训练的数据子集和用于测试的数据子集。</p>
<ul>
<li>分割比例为：80%的数据用于训练，20%用于测试；</li>
<li>选定一个数值以设定 <code>train_test_split</code> 中的 <code>random_state</code> ，这会确保结果的一致性；</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提示： 导入train_test_split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(features, prices, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-3-训练及测试"><a href="#2-3-训练及测试" class="headerlink" title="2.3 训练及测试"></a>2.3 训练及测试</h3><p><em>将数据集按一定比例分为训练用的数据集和测试用的数据集对学习算法有什么好处？</em></p>
<p><em>如果用模型已经见过的数据，例如部分训练集数据进行测试，又有什么坏处？</em> 如果没有数据来对模型进行测试，会出现什么问题？</p>
<ul>
<li>将数据集按照一定比例分割，我们可以合理评估学习算法在面对未知数据时的表现效果</li>
<li>用来评价模型的数据如果不是独立于样本的，则可能评价结果是不准确的情况。我们也无法得出，这个算法是否可以应用在更广泛的情况</li>
</ul>
<hr>
<h2 id="3-模型衡量标准"><a href="#3-模型衡量标准" class="headerlink" title="3. 模型衡量标准"></a>3. 模型衡量标准</h2><p>在项目的第三步中，你需要了解必要的工具和技巧来让你的模型进行预测。用这些工具和技巧对每一个模型的表现做精确的衡量可以极大地增强你预测的信心。</p>
<h3 id="3-1-定义衡量标准"><a href="#3-1-定义衡量标准" class="headerlink" title="3.1 定义衡量标准"></a>3.1 定义衡量标准</h3><p>如果不能对模型的训练和测试的表现进行量化地评估，就很难衡量模型的好坏。一般情况下，我们可以定义一些衡量标准，这些标准可以通过对某些误差或者拟合程度的计算来得到。在这个项目中，你将通过运算<a href="http://stattrek.com/statistics/dictionary.aspx?definition=coefficient_of_determination" target="_blank" rel="noopener"><em>决定系数</em></a> R<sup>2</sup> 来量化模型的表现。模型的决定系数是回归分析中十分常用的统计信息，经常被当作衡量模型预测能力好坏的标准。</p>
<p>R<sup>2</sup>的数值范围从0至1，表示<strong>目标变量</strong>的预测值和实际值之间的相关程度平方的百分比。一个模型的R<sup>2</sup> 值为0还不如直接用<strong>平均值</strong>来预测效果好；而一个R<sup>2</sup> 值为1的模型则可以对目标变量进行完美的预测。从0至1之间的数值，则表示该模型中目标变量中有百分之多少能够用<strong>特征</strong>来解释。<em>模型也可能出现负值的R<sup>2</sup>，这种情况下模型所做预测有时会比直接计算目标变量的平均值差很多。</em></p>
<p>在下方代码的 <code>performance_metric</code> 函数中，我实现了：</p>
<ul>
<li>使用 <code>sklearn.metrics</code> 中的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html" target="_blank" rel="noopener"><code>r2_score</code></a> 来计算 <code>y_true</code> 和 <code>y_predict</code>的R<sup>2</sup>值，作为对其表现的评判。</li>
<li>将他们的表现评分储存到<code>score</code>变量中。</li>
</ul>
<p>或（:这个并没有实现:）</p>
<ul>
<li>(可选) 不使用任何外部库，参考<a href="https://en.wikipedia.org/wiki/Coefficient_of_determination" target="_blank" rel="noopener">决定系数的定义</a>进行计算，这也可以帮助你更好的理解决定系数在什么情况下等于0或等于1。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入r2_score</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">performance_metric</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="string">"""计算并返回预测值相比于预测值的分数"""</span></span><br><span class="line">    </span><br><span class="line">    score = r2_score(y_true, y_predict)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不导入任何计算决定系数的库</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">performance_metric2</span><span class="params">(y_true, y_predict)</span>:</span></span><br><span class="line">    <span class="string">"""计算并返回预测值相比于预测值的分数"""</span></span><br><span class="line">    </span><br><span class="line">    score = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>

<h3 id="3-2-拟合程度"><a href="#3-2-拟合程度" class="headerlink" title="3.2 拟合程度"></a>3.2 拟合程度</h3><p>假设一个数据集有五个数据且一个模型做出下列目标变量的预测：</p>
<table>
<thead>
<tr>
<th align="center">真实数值</th>
<th align="center">预测数值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">3.0</td>
<td align="center">2.5</td>
</tr>
<tr>
<td align="center">-0.5</td>
<td align="center">0.0</td>
</tr>
<tr>
<td align="center">2.0</td>
<td align="center">2.1</td>
</tr>
<tr>
<td align="center">7.0</td>
<td align="center">7.8</td>
</tr>
<tr>
<td align="center">4.2</td>
<td align="center">5.3</td>
</tr>
</tbody></table>
<p><em>怎么样可以判断，这个模型已成功地描述了目标变量的变化？</em>  </p>
<p>通过运行下方的代码，我可以使用<code>performance_metric</code>函数来计算模型的决定系数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算这个模型的预测结果的决定系数</span></span><br><span class="line">score = performance_metric([<span class="number">3</span>, <span class="number">-0.5</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">4.2</span>], [<span class="number">2.5</span>, <span class="number">0.0</span>, <span class="number">2.1</span>, <span class="number">7.8</span>, <span class="number">5.3</span>])</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Model has a coefficient of determination, R^2, of &#123;:.3f&#125;."</span>.format(score)</span><br></pre></td></tr></table></figure>

<pre><code>Model has a coefficient of determination, R^2, of 0.923.</code></pre><ul>
<li>这个模型以及较为成功地描述了目标变量的变化。</li>
<li>因为可以看到 R^2 计算结果为 0.923 意味着数据超过90的部分能够使用模型进行特征的描述和预测</li>
</ul>
<hr>
<h2 id="4-分析模型的表现"><a href="#4-分析模型的表现" class="headerlink" title="4. 分析模型的表现"></a>4. 分析模型的表现</h2><p>在项目的第四步，可以来看一下不同参数下，模型在训练集和验证集上的表现。<br>我只是用了一个特定的算法（带剪枝的决策树），在参数选择上，这个算法只包括了选择参数 <code>&#39;max_depth&#39;</code>。<br>我会用全部训练集训练，但选择不同<code>&#39;max_depth&#39;</code> 参数，观察这个参数的变化如何影响模型的表现。<br>最后，画出模型的表现来对于分析过程十分有益，这可以让我直观地看到模型的表现。</p>
<h3 id="4-1-学习曲线"><a href="#4-1-学习曲线" class="headerlink" title="4.1 学习曲线"></a>4.1 学习曲线</h3><ul>
<li>下方区域内的代码可以输出四幅图像，他们分别表现了一个决策树模型在不同最大深度下的表现。</li>
<li>每一条曲线都直观得显示了随着训练数据量的增加，模型学习曲线的在训练集评分和验证集评分的变化。</li>
<li>评分使用决定系数R<sup>2</sup>。曲线的阴影区域代表的是该曲线的不确定性（用标准差衡量）。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据不同的训练集大小，和最大深度，生成学习曲线</span></span><br><span class="line">vs.ModelLearning(X_train, y_train)</span><br></pre></td></tr></table></figure>


<p><img src="/images/output_22_0.png" alt="png"></p>
<h3 id="4-2-对学习曲线的观察"><a href="#4-2-对学习曲线的观察" class="headerlink" title="4.2 对学习曲线的观察"></a>4.2 对学习曲线的观察</h3><p>所以从上面的图形中，我应该怎么决定合适的最大深度呢？</p>
<p>其次，随着寻来拿数据量的增加，训练集曲线的评分正在发生变化，验证集曲线也有变化。我也需要考虑数据继续增加的情况下，如何保持或者有效提升模型的表现呢？但是学习曲线看上去最终都很稳定，是不是会最终收敛到一个特定的值。</p>
<ul>
<li>我想选择 max = 3，也就是将深度设定为3.</li>
<li>从曲线的观察上来看，随着训练数据量的增加，训练集曲线评分降低了一点，但趋于稳定。</li>
<li>随着训练数据量的增加，验证集曲线迅速上升后也趋于稳定</li>
<li>如果有更多训练数据，且新训练数据分布和现有相同，模型的表现不会有什么明显提升，因为现在已经能够捕捉数据的全部特征了。</li>
</ul>
<h3 id="4-3-复杂度曲线"><a href="#4-3-复杂度曲线" class="headerlink" title="4.3 复杂度曲线"></a>4.3 复杂度曲线</h3><p>下列代码内的区域会输出一幅图像，用于展示了一个已经经过训练和验证的决策树模型在不同最大深度条件下的表现。</p>
<p>这个图形将包含两条曲线，一个是训练集的变化，一个是验证集的变化。跟<strong>学习曲线</strong>相似，阴影区域代表该曲线的不确定性，模型训练和测试部分的评分都用的 <code>performance_metric</code> 函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据不同的最大深度参数，生成复杂度曲线</span></span><br><span class="line">vs.ModelComplexity(X_train, y_train)</span><br></pre></td></tr></table></figure>


<p><img src="/images/output_26_0.png" alt="png"></p>
<h3 id="4-4-偏差（bias）与方差（variance）之间的权衡取舍"><a href="#4-4-偏差（bias）与方差（variance）之间的权衡取舍" class="headerlink" title="4.4 偏差（bias）与方差（variance）之间的权衡取舍"></a>4.4 偏差（bias）与方差（variance）之间的权衡取舍</h3><p><em>当模型以最大深度 1训练时，模型的预测是出现很大的偏差还是出现了很大的方差？当模型以最大深度10训练时，情形又如何呢？图形中的哪些特征能够支持你的结论？</em></p>
<p> 我要如何判断模型是否出现了偏差很大或者方差很大的问题？</p>
<ul>
<li>模型深度为 1 时，偏差大。</li>
<li>因为可以看到模型预测在训练集上的得分低，说明模型预测不准确。</li>
<li>而当模型深度为 10 时，方差大。</li>
<li>可以看到模型预测在训练集上的得分高，接近1，说明预测准确。但模型在训练集上表现较好，但测试集上表现差，说明面对新数据时表现不好。</li>
</ul>
<h3 id="4-5-最优模型的猜测"><a href="#4-5-最优模型的猜测" class="headerlink" title="4.5 最优模型的猜测"></a>4.5 最优模型的猜测</h3><p>我应该选择哪一个最大深度，才能对未来（未知）的数据进行预测。</p>
<ul>
<li>按照图 5 来看可以选择深度为 6 的模型。</li>
<li>个人认为，深度为 4 时，方差最小，但偏差仅仅超过0.8。</li>
<li>随着深度增加，偏差仍在迅速缩小，而在 6 之后，偏差开始趋于稳定，处在0.9左右。</li>
<li>此时方差看上去增大了0.1左右，可以接受。</li>
</ul>
<hr>
<h2 id="5-选择最优参数"><a href="#5-选择最优参数" class="headerlink" title="5. 选择最优参数"></a>5. 选择最优参数</h2><h3 id="5-1-网格搜索（Grid-Search）"><a href="#5-1-网格搜索（Grid-Search）" class="headerlink" title="5.1 网格搜索（Grid Search）"></a>5.1 网格搜索（Grid Search）</h3><p><em>什么是网格搜索法？如何用它来优化模型？</em></p>
<ul>
<li>网格搜索，是一种系统地遍历多种参数组合，通过交叉验证确定最佳效果参数的方法</li>
<li>使用网格搜索优化模型，可以对不同参数组合进行评估，得到最合适的参数组合，优化模型</li>
</ul>
<h3 id="5-2-交叉验证"><a href="#5-2-交叉验证" class="headerlink" title="5.2 交叉验证"></a>5.2 交叉验证</h3><ul>
<li>什么是K折交叉验证法（k-fold cross-validation）？</li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" target="_blank" rel="noopener">GridSearchCV</a>是如何结合交叉验证来完成对最佳参数组合的选择的？</li>
<li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" target="_blank" rel="noopener">GridSearchCV</a>中的<code>&#39;cv_results_&#39;</code>属性能告诉我们什么？</li>
<li>网格搜索时如果不使用交叉验证会有什么问题？交叉验证又是如何解决这个问题的？</li>
</ul>
<p>在下面 fit_model函数最后加入 <code>print pd.DataFrame(grid.cv_results_)</code> 可以查看更多信息。</p>
<ol>
<li><p>什么是K折交叉验证法（k-fold cross-validation）？</p>
<ul>
<li>K折交叉验证，是将训练数据（验证集）平分到 k 个容器。在每次实验时，选择其中 1 个容器中的数据作为验证集，其他（k-1）个容器作为训练集。</li>
<li>继续训练模型，并进行验证。</li>
<li>交叉验证会在过程中进行 k 次实验，然后取得 k 次实验测试结果的平均值。</li>
</ul>
</li>
<li><p>网格搜索如何结合交叉验证完成最佳参数选择？</p>
<ul>
<li>这种方法中我们对每 1 个参数组合进行 1 次 K 折较差验证，得到平均分数。</li>
<li>一般选择均分最高的参数组合作为最优参数，但如果品分标准是loss，会选择评分最低的参数组合。</li>
</ul>
</li>
<li><p>cv_results_属性代表什么？</p>
<ul>
<li>cv_results_可以用来来获得最优参数组合</li>
<li>它返回了一个字典，其中记录了每一组网格参数每一次实验时的结果，如时间、评估值、其他统计信息</li>
</ul>
</li>
<li><p>网格搜索时如果不使用交叉验证会有什么问题？交叉验证又是如何解决这个问题的？</p>
<ul>
<li>网格搜索不使用交叉验证时所花费的训练时间更短，但模型参数并不是最优；</li>
<li>交叉验证进行更多次的试验，使用了全部训练集，能够对每一个参数组合得出更准确的评分。</li>
</ul>
</li>
</ol>
<h3 id="5-3-决策树算法"><a href="#5-3-决策树算法" class="headerlink" title="5.3 决策树算法"></a>5.3 决策树算法</h3><p>下面，我会使用<strong>决策树算法</strong>训练一个模型。</p>
<p>为了得出的是一个最优模型，我需要使用网格搜索法训练模型，以找到最佳的 <code>&#39;max_depth&#39;</code> 参数。我可以把<code>&#39;max_depth&#39;</code> 参数理解为决策树算法在做出预测前，可以允许的对数据提出问题的数量。而决策树也是<strong>监督学习算法</strong>中的一种。</p>
<p>在下方 <code>fit_model</code> 函数中，我进行了如下的定义：</p>
<ol>
<li><strong>定义 <code>&#39;cross_validator&#39;</code> 变量</strong>: 使用 <code>sklearn.model_selection</code> 中的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html" target="_blank" rel="noopener"><code>KFold</code></a> 创建一个交叉验证生成器对象;</li>
<li><strong>定义 <code>&#39;regressor&#39;</code> 变量</strong>: 使用  <code>sklearn.tree</code> 中的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html" target="_blank" rel="noopener"><code>DecisionTreeRegressor</code></a> 创建一个决策树的回归函数;</li>
<li><strong>定义 <code>&#39;params&#39;</code> 变量</strong>: 为 <code>&#39;max_depth&#39;</code> 参数创造一个字典，它的值是从1至10的数组;</li>
<li><strong>定义 <code>&#39;scoring_fnc&#39;</code> 变量</strong>: 使用 <code>sklearn.metrics</code> 中的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html" target="_blank" rel="noopener"><code>make_scorer</code></a>  创建一个评分函数；<br>将 <code>‘performance_metric’</code> 作为参数传至这个函数中；</li>
<li><strong>定义 <code>&#39;grid&#39;</code> 变量</strong>: 使用 <code>sklearn.model_selection</code> 中的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" target="_blank" rel="noopener"><code>GridSearchCV</code></a> 创建一个网格搜索对象；将变量<code>&#39;regressor&#39;</code>, <code>&#39;params&#39;</code>, <code>&#39;scoring_fnc&#39;</code>和 <code>&#39;cross_validator&#39;</code> 作为参数传至这个对象构造函数中；</li>
</ol>
<p>关于python函数的默认参数定义和传递，可以参考的资料是，这个MIT课程的<a href="http://cn-static.udacity.com/mlnd/videos/MIT600XXT114-V004200_DTH.mp4" target="_blank" rel="noopener">视频</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#提示: 导入 'KFold' 'DecisionTreeRegressor' 'make_scorer' 'GridSearchCV' </span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold,GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> make_scorer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_model</span><span class="params">(X, y)</span>:</span></span><br><span class="line">    <span class="string">""" 基于输入数据 [X,y]，利于网格搜索找到最优的决策树模型"""</span></span><br><span class="line">    </span><br><span class="line">    cross_validator = KFold(n_splits=<span class="number">10</span>)</span><br><span class="line">    </span><br><span class="line">    regressor =  DecisionTreeRegressor()</span><br><span class="line"></span><br><span class="line">    params = &#123;<span class="string">'max_depth'</span>:range(<span class="number">1</span>,<span class="number">11</span>)&#125;</span><br><span class="line"></span><br><span class="line">    scoring_fnc = make_scorer(performance_metric)</span><br><span class="line"></span><br><span class="line">    grid = GridSearchCV(regressor, params, scoring=scoring_fnc,cv=cross_validator)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 基于输入数据 [X,y]，进行网格搜索</span></span><br><span class="line">    grid = grid.fit(X, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回网格搜索后的最优模型</span></span><br><span class="line">    <span class="keyword">return</span> grid.best_estimator_</span><br></pre></td></tr></table></figure>

<h3 id="5-4-训练最优模型（-没有实现）"><a href="#5-4-训练最优模型（-没有实现）" class="headerlink" title="5.4 训练最优模型（*没有实现）"></a>5.4 训练最优模型（*没有实现）</h3><p>另外一种方法是在下方 <code>fit_model</code> 函数中：</p>
<ul>
<li>遍历参数<code>‘max_depth’</code>的可选值 1～10，构造对应模型</li>
<li>计算当前模型的交叉验证分数</li>
<li>返回最优交叉验证分数对应的模型</li>
</ul>
<p>但这一个方法还没有完成。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Not finished!</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">不允许使用 DecisionTreeRegressor 以外的任何 sklearn 库</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">提示: 你可能需要实现下面的 cross_val_score 函数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">def cross_val_score(estimator, X, y, scoring = performance_metric, cv=3):</span></span><br><span class="line"><span class="string">    """ 返回每组交叉验证的模型分数的数组 """</span></span><br><span class="line"><span class="string">    scores = [0,0,0]</span></span><br><span class="line"><span class="string">    return scores</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_model2</span><span class="params">(X, y)</span>:</span></span><br><span class="line">    <span class="string">""" 基于输入数据 [X,y]，利于网格搜索找到最优的决策树模型"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#最优交叉验证分数对应的最优模型</span></span><br><span class="line">    best_estimator = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> best_estimator</span><br></pre></td></tr></table></figure>

<h3 id="5-5-最优模型"><a href="#5-5-最优模型" class="headerlink" title="5.5 最优模型"></a>5.5 最优模型</h3><p><em>最优模型的最大深度（maximum depth）是多少？</em></p>
<p>通过下面的代码，我能够将决策树回归函数代入训练数据的集合，以得到最优化的模型。并得到最大深度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于训练数据，获得最优模型</span></span><br><span class="line">optimal_reg = fit_model(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出最优模型的 'max_depth' 参数</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Parameter 'max_depth' is &#123;&#125; for the optimal model."</span>.format(optimal_reg.get_params()[<span class="string">'max_depth'</span>])</span><br></pre></td></tr></table></figure>

<pre><code>Parameter &apos;max_depth&apos; is 4 for the optimal model.</code></pre><p>可以看到，此时的最大深度为4，和我开始目测的不同。</p>
<h2 id="6-做出预测"><a href="#6-做出预测" class="headerlink" title="6. 做出预测"></a>6. 做出预测</h2><p>当我们用数据训练出一个模型，它现在就可用于对新的数据进行预测。在决策树回归函数中，模型已经学会对新输入的数据<em>提问</em>，并返回对<strong>目标变量</strong>的预测值。你可以用这个预测来获取数据未知目标变量的信息，这些数据必须是不包含在训练数据之内的。</p>
<h3 id="6-1-预测销售价格"><a href="#6-1-预测销售价格" class="headerlink" title="6.1 预测销售价格"></a>6.1 预测销售价格</h3><p>接下来由于模型已经得到了，我需要开始应用这个模型处理一些问题。</p>
<p>假设我是一个在波士顿地区的房屋经纪人，我可以使用此模型以帮助你的客户评估他们想出售的房屋。</p>
<p>假设你已经从你的三个客户收集到以下的资讯:</p>
<table>
<thead>
<tr>
<th align="center">特征</th>
<th align="center">客戶 1</th>
<th align="center">客戶 2</th>
<th align="center">客戶 3</th>
</tr>
</thead>
<tbody><tr>
<td align="center">房屋内房间总数</td>
<td align="center">5 间房间</td>
<td align="center">4 间房间</td>
<td align="center">8 间房间</td>
</tr>
<tr>
<td align="center">社区贫困指数（％被认为是贫困阶层）</td>
<td align="center">17%</td>
<td align="center">32%</td>
<td align="center">3%</td>
</tr>
<tr>
<td align="center">邻近学校的学生-老师比例</td>
<td align="center">15：1</td>
<td align="center">22：1</td>
<td align="center">12：1</td>
</tr>
</tbody></table>
<p><em>那么接下来，我需要给每位客户的房屋销售的价格进行建议？并通过房屋特征的数值提供对于价格的合理判断。</em> </p>
<p>运行下列的代码区域，我就可以使用优化的模型来为每位客户的房屋价值做出预测。并结合我在第一步中数据分析的阶段，计算出来的部分统计信息来辅助证明我的模型是否正确。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成三个客户的数据</span></span><br><span class="line">client_data = [[<span class="number">5</span>, <span class="number">17</span>, <span class="number">15</span>], <span class="comment"># 客户 1</span></span><br><span class="line">               [<span class="number">4</span>, <span class="number">32</span>, <span class="number">22</span>], <span class="comment"># 客户 2</span></span><br><span class="line">               [<span class="number">8</span>, <span class="number">3</span>, <span class="number">12</span>]]  <span class="comment"># 客户 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">predicted_price = optimal_reg.predict(client_data)</span><br><span class="line"><span class="keyword">for</span> i, price <span class="keyword">in</span> enumerate(predicted_price):</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Predicted selling price for Client &#123;&#125;'s home: $&#123;:,.2f&#125;"</span>.format(i+<span class="number">1</span>, price)</span><br></pre></td></tr></table></figure>

<pre><code>Predicted selling price for Client 1&apos;s home: $409,100.00
Predicted selling price for Client 2&apos;s home: $285,600.00
Predicted selling price for Client 3&apos;s home: $957,218.18</code></pre><ul>
<li><p>预测价值为409100、285600、957218 美元。</p>
</li>
<li><p>从房屋特征来看，房屋质量的高中低档水平应该是 客户 3 （高档）&gt; 客户 1 （中档）&gt; 客户 2（低档） 。</p>
</li>
<li><p>从统计数据来看，客户 1 的房屋价值处在 Min 与 Max 之间，接近均价和中位数。客户 2 的房屋价值较低，只稍微比 Min 高一点。客户 3 的房屋价值较高，接近 Max 价格。符合房屋特征的判断，因此预测还是是比较合理的。</p>
</li>
</ul>
<h3 id="6-2-使用模型进行预测"><a href="#6-2-使用模型进行预测" class="headerlink" title="6.2 使用模型进行预测"></a>6.2 使用模型进行预测</h3><p>我对三个客户的房子的售价进行了预测。接下来，我会使用我的最优模型在整个测试数据上进行预测, 并计算相对于目标变量的决定系数 R<sup>2</sup>的值**。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 提示：你可能需要用到 X_test, y_test, optimal_reg, performance_metric</span></span><br><span class="line"><span class="comment"># 提示：你可能需要参考问题10的代码进行预测</span></span><br><span class="line"><span class="comment"># 提示：你可能需要参考问题3的代码来计算R^2的值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line">r2 = r2_score(y_test, optimal_reg.predict(X_test))</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Optimal model has R^2 score &#123;:,.2f&#125; on test data"</span>.format(r2)</span><br></pre></td></tr></table></figure>

<pre><code>Optimal model has R^2 score 0.78 on test data</code></pre><h3 id="6-3-分析决定系数"><a href="#6-3-分析决定系数" class="headerlink" title="6.3 分析决定系数"></a>6.3 分析决定系数</h3><p>刚刚计算了最优模型在测试集上的决定系数，但我应该如何评价这个结果？</p>
<p>结果为 0.78 结果不算太好，但也可以进行基本的房屋价值预测了。</p>
<h3 id="6-4-模型的健壮性"><a href="#6-4-模型的健壮性" class="headerlink" title="6.4 模型的健壮性"></a>6.4 模型的健壮性</h3><p>一个最优的模型不一定是一个健壮模型。有的时候模型会过于复杂或者过于简单，以致于难以泛化新增添的数据；有的时候模型采用的学习算法并不适用于特定的数据结构；有的时候样本本身可能有太多噪点或样本过少，使得模型无法准确地预测目标变量。这些情况下我们会说模型是欠拟合的。</p>
<p>模型是否足够健壮来保证预测的一致性？</p>
<p>下面，我会采用不同的训练和测试集执行 <code>fit_model</code> 函数10次。</p>
<p>对一个特定的客户来说，预测是如何随训练数据的变化而变化的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注释掉 fit_model 函数里的所有 print 语句</span></span><br><span class="line">vs.PredictTrials(features, prices, fit_model, client_data)</span><br></pre></td></tr></table></figure>

<pre><code>Trial 1: $391,183.33
Trial 2: $411,417.39
Trial 3: $415,800.00
Trial 4: $420,622.22
Trial 5: $413,334.78
Trial 6: $411,931.58
Trial 7: $399,663.16
Trial 8: $407,232.00
Trial 9: $402,531.82
Trial 10: $413,700.00

Range in prices: $29,438.89</code></pre><ul>
<li>可以从上述的结果中看到，模型还是没有太不健壮，保持了一定的稳定性。模型随着数据集的变化，最大变化差值为 29438.89 ，约为 7.5% 左右的幅度。</li>
</ul>
<h3 id="6-5-结果分析"><a href="#6-5-结果分析" class="headerlink" title="6.5 结果分析"></a>6.5 结果分析</h3><p>从结果来看，我建构的模型能否在现实世界中使用?</p>
<ul>
<li>1978年所采集的数据，在已考虑通货膨胀的前提下，在今天是否仍然适用？</li>
<li>数据中呈现的特征是否足够描述一个房屋？</li>
<li>在波士顿这样的大都市采集的数据，能否应用在其它乡镇地区</li>
<li>你觉得仅仅凭房屋所在社区的环境来判断房屋价值合理吗</li>
</ul>
<p>不同时代经济发展状况不同，人们的经济观念也不同，房屋价值的模型会随之改变。因此会在今天并不适用。<br>数据中呈现的数据还是比较简化的，没有包括房屋的采光、房体结构、社区成熟度、交通便利性等因素。<br>波士顿城市数据，应该不能应用在乡镇地区。一级城市、二级城市、偏远乡村的整体房屋价值均值相差肯定很大，会让数据集呈现异常，影响模型对特征的判断。<br>不合理，社区环境还不够全面</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Yilin"
      src="/images/avat.JPG">
  <p class="site-author-name" itemprop="name">Yilin</p>
  <div class="site-description" itemprop="description">Thoughts. Notes.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
        
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags">
          
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yilin10" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yilin10" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yilin.zhu@mail.polimi.it" title="E-Mail → mailto:yilin.zhu@mail.polimi.it" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/ilin.chu0" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;ilin.chu0" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2015 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yilin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
